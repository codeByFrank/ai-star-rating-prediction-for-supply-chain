{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b137a3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ  PREDICTION DEMO ‚Äì champion model\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "PREDICTION DEMO ‚Äì JUPYTER NOTEBOOK\n",
    "==================================\n",
    "Loads the champion classification model and evaluates it on a\n",
    "small, stratified set of hold-out reviews.\n",
    "\n",
    "The notebook is organised in clear, numbered sections:\n",
    "    1) File checks\n",
    "    2) Load model + artefacts\n",
    "    3) Prepare test data\n",
    "    4) Select a stratified sample\n",
    "    5) Run predictions\n",
    "    6) Performance metrics\n",
    "    7) Per-review diagnostics\n",
    "\"\"\"\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Standard libraries\n",
    "# ------------------------------------------------------------------\n",
    "import pickle\n",
    "import random\n",
    "import textwrap\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Third-party libraries\n",
    "# ------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report,\n",
    "    mean_absolute_error, confusion_matrix\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "print(\"üöÄ  PREDICTION DEMO ‚Äì champion model\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dab4c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ File availability:\n",
      "   ‚úÖ Model bundle\n",
      "   ‚úÖ Feature metadata\n",
      "   ‚úÖ Train/Test splits\n",
      "   ‚úÖ Pre-processed CSV\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1) CHECK REQUIRED FILES & PATHS\n",
    "# =============================================================================\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL_PKL   = Path(\"../src/models/best_classification_model.pkl\")\n",
    "FEAT_PKL    = Path(\"../src/models/feature_info.pkl\")\n",
    "SPLIT_PKL   = Path(\"../src/models/train_test_splits.pkl\")\n",
    "DEFAULT_CSV = Path(\"../src/data/processed/temu_reviews_preprocessed.csv\")\n",
    "\n",
    "print(\"üìÇ File availability:\")\n",
    "file_flags = {\n",
    "    \"Model bundle\"       : MODEL_PKL.exists(),\n",
    "    \"Feature metadata\"   : FEAT_PKL.exists(),\n",
    "    \"Train/Test splits\"  : SPLIT_PKL.exists(),\n",
    "    \"Pre-processed CSV\"  : DEFAULT_CSV.exists()\n",
    "}\n",
    "\n",
    "for label, ok in file_flags.items():\n",
    "    mark = \"‚úÖ\" if ok else \"‚ùå\"\n",
    "    print(f\"   {mark} {label}\")\n",
    "\n",
    "missing_core = [name for name, ok in file_flags.items()\n",
    "                if not ok and name in {\"Model bundle\", \"Feature metadata\"}]\n",
    "\n",
    "if missing_core:\n",
    "    msg = \", \".join(missing_core)\n",
    "    raise FileNotFoundError(\n",
    "        f\"Critical file(s) missing: {msg}. \"\n",
    "        \"Please run the training notebook first.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62f8b555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ Loading model artefacts ‚Ä¶\n",
      "‚úÖ Model loaded : Stacking\n",
      "   Weighted F1  : 0.725\n",
      "   Test accuracy: 0.733\n",
      "‚úÖ Vectoriser loaded : 5,000 features\n",
      "‚úÖ Numerical columns : ['word_count', 'char_count', 'sentence_count', 'avg_word_length', 'exclamation_count', 'question_count', 'capital_ratio', 'sentiment_compound', 'sentiment_pos', 'sentiment_neu', 'sentiment_neg']\n",
      "‚úÖ Class weights     : {np.int64(1): np.float64(0.38278940027894004), np.int64(2): np.float64(3.1510907003444317), np.int64(3): np.float64(4.235493827160494), np.int64(4): np.float64(2.463734290843806), np.int64(5): np.float64(0.7001530612244898)}\n",
      "‚úÖ Label encoder loaded from feature_info\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 2) LOAD MODEL AND SUPPORT FILES\n",
    "# =============================================================================\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "MODEL_PKL = Path(\"../src/models/best_classification_model.pkl\")\n",
    "FEAT_PKL  = Path(\"../src/models/feature_info.pkl\")\n",
    "\n",
    "print(\"\\nüì¶ Loading model artefacts ‚Ä¶\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1) Load the champion model bundle\n",
    "# ------------------------------------------------------------------\n",
    "try:\n",
    "    with MODEL_PKL.open(\"rb\") as fp:\n",
    "        mdl_dict = pickle.load(fp)\n",
    "\n",
    "    clf        = mdl_dict[\"model\"]          # fitted estimator\n",
    "    model_name = mdl_dict[\"model_name\"]\n",
    "    test_acc   = mdl_dict.get(\"test_accuracy\", \"N/A\")\n",
    "    w_f1       = mdl_dict.get(\"weighted_f1\", \"N/A\")\n",
    "\n",
    "    print(f\"‚úÖ Model loaded : {model_name}\")\n",
    "    if w_f1 != \"N/A\":\n",
    "        print(f\"   Weighted F1  : {w_f1:.3f}\")\n",
    "    if test_acc != \"N/A\":\n",
    "        print(f\"   Test accuracy: {test_acc:.3f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"‚ùå Could not load model pickle: {e}\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2) Load vectoriser & metadata\n",
    "# ------------------------------------------------------------------\n",
    "try:\n",
    "    with FEAT_PKL.open(\"rb\") as fp:\n",
    "        feat = pickle.load(fp)\n",
    "\n",
    "    vectorizer         = feat[\"tfidf_vectorizer\"]\n",
    "    feature_count      = feat.get(\"feature_count\",\n",
    "                                  len(vectorizer.get_feature_names_out()))\n",
    "    numerical_features = feat.get(\"numerical_features\", [])\n",
    "    class_weights      = feat.get(\"class_weights\", {})\n",
    "    label_encoder      = feat.get(\"label_encoder\")  # may be None\n",
    "\n",
    "    print(f\"‚úÖ Vectoriser loaded : {feature_count:,} features\")\n",
    "    print(f\"‚úÖ Numerical columns : {numerical_features}\")\n",
    "    if class_weights:\n",
    "        print(f\"‚úÖ Class weights     : {class_weights}\")\n",
    "    if label_encoder is None:\n",
    "        # fall-back: identity encoder 1‚òÖ‚Ä¶5‚òÖ ‚Üí 0‚Ä¶4\n",
    "        label_encoder = LabelEncoder().fit([1, 2, 3, 4, 5])\n",
    "        print(\"üîß Label encoder created (identity 1-5 ‚Üí 0-4)\")\n",
    "    else:\n",
    "        print(\"‚úÖ Label encoder loaded from feature_info\")\n",
    "\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"‚ùå Could not load feature artefacts: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d202aa37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Preparing test data ‚Ä¶\n",
      "üìã Using stored train/test splits ‚Ä¶\n",
      "‚úÖ Test split loaded : 2,745 samples (5,011 features)\n",
      "   Rating distribution: {1: np.int64(1434), 2: np.int64(174), 3: np.int64(130), 4: np.int64(223), 5: np.int64(784)}\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 3) PREPARE TEST DATA\n",
    "# =============================================================================\n",
    "import pickle, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"\\nüìä Preparing test data ‚Ä¶\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# paths\n",
    "# ------------------------------------------------------------------\n",
    "SPLIT_PKL   = Path(\"../src/models/train_test_splits.pkl\")\n",
    "DEFAULT_CSV = Path(\"../data/preprocessed_reviews.csv\")\n",
    "\n",
    "# make sure numerical_features exists\n",
    "if \"numerical_features\" not in globals():\n",
    "    numerical_features = []      # will be updated later if CSV contains them\n",
    "\n",
    "# decide which source to use\n",
    "use_splits = SPLIT_PKL.exists()\n",
    "use_csv    = DEFAULT_CSV.exists() and not use_splits\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1) load saved train/test splits\n",
    "# ------------------------------------------------------------------\n",
    "if use_splits:\n",
    "    print(\"üìã Using stored train/test splits ‚Ä¶\")\n",
    "    try:\n",
    "        with SPLIT_PKL.open(\"rb\") as fp:\n",
    "            splits = pickle.load(fp)\n",
    "\n",
    "        X_test  = splits[\"combined\"][\"X_test\"]\n",
    "        y_test  = splits[\"combined\"][\"y_test\"]\n",
    "        print(f\"‚úÖ Test split loaded : {X_test.shape[0]:,} samples \"\n",
    "              f\"({X_test.shape[1]:,} features)\")\n",
    "        print(f\"   Rating distribution: {dict(pd.Series(y_test).value_counts().sort_index())}\")\n",
    "        data_source = \"splits\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not load splits: {e}\")\n",
    "        use_splits = False\n",
    "        use_csv    = DEFAULT_CSV.exists()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2) fallback: load the pre-processed CSV\n",
    "# ------------------------------------------------------------------\n",
    "if use_csv and not use_splits:\n",
    "    print(\"üìã Using pre-processed CSV ‚Ä¶\")\n",
    "    try:\n",
    "        df = pd.read_csv(DEFAULT_CSV)\n",
    "        df = df.dropna(subset=[\"processed_text\", \"ReviewRating\"])\n",
    "        df[\"ReviewRating\"] = df[\"ReviewRating\"].astype(int)\n",
    "        df = df[df[\"ReviewRating\"].between(1, 5)]        # keep ratings 1-5\n",
    "\n",
    "        print(f\"‚úÖ CSV loaded : {len(df):,} valid reviews\")\n",
    "        print(f\"   Rating distribution: {dict(df['ReviewRating'].value_counts().sort_index())}\")\n",
    "\n",
    "        # check which numeric columns are present\n",
    "        avail_num   = [c for c in numerical_features if c in df.columns]\n",
    "        missing_num = [c for c in numerical_features if c not in df.columns]\n",
    "        if missing_num:\n",
    "            print(f\"‚ö†Ô∏è Missing numeric features: {missing_num}\")\n",
    "            print(f\"‚úÖ Available numeric features: {avail_num}\")\n",
    "            numerical_features = avail_num      # update list\n",
    "\n",
    "        data_source = \"csv\"\n",
    "\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"‚ùå Could not load CSV: {e}\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3) no data found\n",
    "# ------------------------------------------------------------------\n",
    "if not use_splits and not use_csv:\n",
    "    raise FileNotFoundError(\"No test data available: neither split pickle nor CSV found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fdbcc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé≤ Selecting stratified test samples ‚Ä¶\n",
      "‚úÖ Sample size: 15\n",
      "   Rating distribution: {1: np.int64(3), 2: np.int64(3), 3: np.int64(3), 4: np.int64(3), 5: np.int64(3)}\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 4) SELECT A STRATIFIED SAMPLE\n",
    "# =============================================================================\n",
    "import numpy as np, random\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(\"\\nüé≤ Selecting stratified test samples ‚Ä¶\")\n",
    "\n",
    "N_SAMPLES = 15          # total reviews to inspect\n",
    "rng       = np.random.default_rng(42)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Helper to pick k indices per star rating\n",
    "# -----------------------------------------------------------\n",
    "def stratified_indices(labels, k_total):\n",
    "    \"\"\"Return <=k_total indices, equally split across present ratings.\"\"\"\n",
    "    unique = np.unique(labels)\n",
    "    k_per  = max(1, k_total // len(unique))\n",
    "    idx = []\n",
    "    for star in unique:\n",
    "        star_idx = np.where(labels == star)[0].tolist()\n",
    "        take = min(k_per, len(star_idx))\n",
    "        idx.extend(rng.choice(star_idx, size=take, replace=False))\n",
    "    # top-up if we‚Äôre short\n",
    "    if len(idx) < k_total:\n",
    "        remaining = [i for i in range(len(labels)) if i not in idx]\n",
    "        extra = rng.choice(remaining, size=k_total-len(idx), replace=False)\n",
    "        idx.extend(extra)\n",
    "    return idx[:k_total]\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# A) use stored splits\n",
    "# -----------------------------------------------------------\n",
    "if data_source == \"splits\":\n",
    "    labels = np.array(y_test)\n",
    "    idx    = stratified_indices(labels, N_SAMPLES)\n",
    "\n",
    "    X_sample  = X_test[idx]\n",
    "    y_true    = labels[idx]\n",
    "    sample_texts = None   # raw text is not part of the split object\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# B) use CSV   (df already loaded earlier)\n",
    "# -----------------------------------------------------------\n",
    "elif data_source == \"csv\":\n",
    "    idx_df = stratified_indices(df[\"ReviewRating\"].values, N_SAMPLES)\n",
    "    samples_df = df.iloc[idx_df].reset_index(drop=True)\n",
    "\n",
    "    # Which feature combo did the model expect?\n",
    "    combo = mdl_dict.get(\"feature_combination\", \"combined\")\n",
    "    print(f\"üîß Model expects feature set: {combo}\")\n",
    "\n",
    "    # ---- TF-IDF block\n",
    "    X_tfidf = vectorizer.transform(samples_df[\"processed_text\"])\n",
    "\n",
    "    # ---- numerical block (if any)\n",
    "    if numerical_features:\n",
    "        X_num = samples_df[numerical_features].values\n",
    "        if \"scaler\" in feature_info:\n",
    "            scaler = feature_info[\"scaler\"]        # trained scaler\n",
    "            X_num_scaled = scaler.transform(X_num)\n",
    "        else:                                      # fallback (not ideal)\n",
    "            print(\"‚ö†Ô∏è  Using fresh StandardScaler ‚Äì may distort results\")\n",
    "            X_num_scaled = StandardScaler().fit_transform(X_num)\n",
    "    else:\n",
    "        X_num_scaled = None\n",
    "\n",
    "    # ---- build X_sample according to combo\n",
    "    if combo == \"tfidf_only\":\n",
    "        X_sample = X_tfidf\n",
    "    elif combo == \"numerical_only\":\n",
    "        if X_num_scaled is None:\n",
    "            raise ValueError(\"Model requires numeric features but none are present.\")\n",
    "        X_sample = X_num_scaled\n",
    "    else:   # combined\n",
    "        if X_num_scaled is None:\n",
    "            print(\"‚ö†Ô∏è Model expects combined features, but numeric part is missing. Falling back to TF-IDF only.\")\n",
    "            X_sample = X_tfidf\n",
    "        else:\n",
    "            X_sample = hstack([X_tfidf, X_num_scaled])\n",
    "\n",
    "    y_true       = samples_df[\"ReviewRating\"].values\n",
    "    sample_texts = samples_df[\"processed_text\"].values\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Summary\n",
    "# -----------------------------------------------------------\n",
    "print(f\"‚úÖ Sample size: {len(y_true)}\")\n",
    "print(f\"   Rating distribution: {dict(pd.Series(y_true).value_counts().sort_index())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08e7b82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÆ Generating predictions ‚Ä¶\n",
      "üîß Raw model output (unique): [np.int64(3)]\n",
      "‚úÖ Model uses 1‚Äì5 encoding\n",
      "‚úÖ Mean confidence: 32.5%\n",
      "üìä Confidence distribution:\n",
      "   <50%   : 15 sample(s)\n",
      "\n",
      "üîç First five predictions:\n",
      "   Sample 1: true 1‚òÖ ‚Üí pred 3‚òÖ (conf: 31.4%)\n",
      "   Sample 2: true 1‚òÖ ‚Üí pred 3‚òÖ (conf: 35.2%)\n",
      "   Sample 3: true 1‚òÖ ‚Üí pred 3‚òÖ (conf: 32.0%)\n",
      "   Sample 4: true 2‚òÖ ‚Üí pred 3‚òÖ (conf: 33.6%)\n",
      "   Sample 5: true 2‚òÖ ‚Üí pred 3‚òÖ (conf: 35.4%)\n",
      "‚úÖ Predictions generated successfully\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 5) MAKE PREDICTIONS\n",
    "# =============================================================================\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\nüîÆ Generating predictions ‚Ä¶\")\n",
    "\n",
    "try:\n",
    "    # -----------------------------------------------------------\n",
    "    # 1) Raw model output (encoded labels)\n",
    "    # -----------------------------------------------------------\n",
    "    y_pred_enc = clf.predict(X_sample)\n",
    "    print(f\"üîß Raw model output (unique): {sorted(set(y_pred_enc))}\")\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # 2) Detect the label scheme and map to 1-5 stars\n",
    "    # -----------------------------------------------------------\n",
    "    if np.min(y_pred_enc) >= 1 and np.max(y_pred_enc) <= 5:\n",
    "        # model is already on 1-5 scale\n",
    "        y_pred = y_pred_enc\n",
    "        print(\"‚úÖ Model uses 1‚Äì5 encoding\")\n",
    "    elif np.min(y_pred_enc) >= 0 and np.max(y_pred_enc) <= 4:\n",
    "        # model is on 0-4 ‚Üí shift\n",
    "        y_pred = y_pred_enc + 1\n",
    "        print(\"‚úÖ Model uses 0‚Äì4 encoding ‚Üí shifted to 1‚Äì5\")\n",
    "    else:\n",
    "        # unexpected range ‚Äì clip as last resort\n",
    "        print(f\"‚ö†Ô∏è Unexpected labels {sorted(set(y_pred_enc))} ‚Äì clipping to 1‚Äì5\")\n",
    "        y_pred = np.clip(y_pred_enc, 1, 5).astype(int)\n",
    "\n",
    "    # final sanity-check\n",
    "    assert y_pred.min() >= 1 and y_pred.max() <= 5, \"label mapping failed\"\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # 3) Confidence scores if available\n",
    "    # -----------------------------------------------------------\n",
    "    if hasattr(clf, \"predict_proba\"):\n",
    "        y_proba    = clf.predict_proba(X_sample)\n",
    "        confidence = y_proba.max(axis=1)\n",
    "        print(f\"‚úÖ Mean confidence: {confidence.mean():.1%}\")\n",
    "\n",
    "        buckets = {\n",
    "            \"<50%\" : confidence < 0.50,\n",
    "            \"50‚Äì70%\" : (confidence >= .50) & (confidence < .70),\n",
    "            \"70‚Äì85%\" : (confidence >= .70) & (confidence < .85),\n",
    "            \"85‚Äì95%\" : (confidence >= .85) & (confidence < .95),\n",
    "            \">95%\"   : confidence >= .95,\n",
    "        }\n",
    "        print(\"üìä Confidence distribution:\")\n",
    "        for label, mask in buckets.items():\n",
    "            count = int(mask.sum())\n",
    "            if count:\n",
    "                print(f\"   {label:<7}: {count} sample(s)\")\n",
    "    else:\n",
    "        confidence = None\n",
    "        print(\"‚ÑπÔ∏è  Model exposes no predict_proba ‚Äì confidence skipped\")\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # 4) Quick preview\n",
    "    # -----------------------------------------------------------\n",
    "    print(\"\\nüîç First five predictions:\")\n",
    "    for i in range(min(5, len(y_pred))):\n",
    "        conf_str = f\" (conf: {confidence[i]:.1%})\" if confidence is not None else \"\"\n",
    "        print(f\"   Sample {i+1}: true {y_true[i]}‚òÖ ‚Üí pred {y_pred[i]}‚òÖ{conf_str}\")\n",
    "\n",
    "    print(\"‚úÖ Predictions generated successfully\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Prediction error: {e}\")\n",
    "    print(\"üîé Debug info:\")\n",
    "    print(f\"   X_sample shape : {getattr(X_sample,'shape',None)}\")\n",
    "    print(f\"   Estimator type : {type(clf)}\")\n",
    "    print(f\"   Model name     : {model_name}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e92c6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà  PERFORMANCE ANALYSIS\n",
      "============================================================\n",
      "üîç Debug:\n",
      "   y_true unique : [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)]\n",
      "   y_pred unique : [np.int64(3)]\n",
      "\n",
      "üéØ Model          : Stacking\n",
      "üìä Accuracy       : 20.0%  (3/15 correct)\n",
      "üìä MAE (in stars) : 1.20\n",
      "\n",
      "üìã CLASSIFICATION REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1‚òÖ      0.000     0.000     0.000         3\n",
      "          2‚òÖ      0.000     0.000     0.000         3\n",
      "          3‚òÖ      0.200     1.000     0.333         3\n",
      "          4‚òÖ      0.000     0.000     0.000         3\n",
      "          5‚òÖ      0.000     0.000     0.000         3\n",
      "\n",
      "    accuracy                          0.200        15\n",
      "   macro avg      0.040     0.200     0.067        15\n",
      "weighted avg      0.040     0.200     0.067        15\n",
      "\n",
      "\n",
      "üîç CONFUSION MATRIX\n",
      "True\\Pred  1‚òÖ  2‚òÖ  3‚òÖ  4‚òÖ  5‚òÖ\n",
      "   1‚òÖ    0   0   3   0   0\n",
      "   2‚òÖ    0   0   3   0   0\n",
      "   3‚òÖ    0   0   3   0   0\n",
      "   4‚òÖ    0   0   3   0   0\n",
      "   5‚òÖ    0   0   3   0   0\n",
      "\n",
      "   Correct predictions : 3/15 (20.0%)\n",
      "   Top confusions:\n",
      "     5‚òÖ ‚Üí 3‚òÖ : 3√ó\n",
      "     4‚òÖ ‚Üí 3‚òÖ : 3√ó\n",
      "     2‚òÖ ‚Üí 3‚òÖ : 3√ó\n",
      "\n",
      "üé≠ PER-CLASS ACCURACY\n",
      "   1‚òÖ : 0.0% (3 samples)\n",
      "   2‚òÖ : 0.0% (3 samples)\n",
      "   3‚òÖ : 100.0% (3 samples)\n",
      "   4‚òÖ : 0.0% (3 samples)\n",
      "   5‚òÖ : 0.0% (3 samples)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 6) PERFORMANCE METRICS\n",
    "# =============================================================================\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, mean_absolute_error,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\nüìà  PERFORMANCE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 1) Quick sanity check\n",
    "# -----------------------------------------------------------\n",
    "print(\"üîç Debug:\")\n",
    "print(f\"   y_true unique : {sorted(set(y_true))}\")\n",
    "print(f\"   y_pred unique : {sorted(set(y_pred))}\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2) Basic metrics\n",
    "# -----------------------------------------------------------\n",
    "acc  = accuracy_score(y_true, y_pred)\n",
    "mae  = mean_absolute_error(y_true, y_pred)\n",
    "hits = (y_true == y_pred).sum()\n",
    "\n",
    "print(f\"\\nüéØ Model          : {model_name}\")\n",
    "print(f\"üìä Accuracy       : {acc:.1%}  ({hits}/{len(y_true)} correct)\")\n",
    "print(f\"üìä MAE (in stars) : {mae:.2f}\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3) Classification report\n",
    "# -----------------------------------------------------------\n",
    "labels       = [1, 2, 3, 4, 5]\n",
    "target_names = [f\"{i}‚òÖ\" for i in labels]\n",
    "print(\"\\nüìã CLASSIFICATION REPORT\")\n",
    "print(\n",
    "    classification_report(\n",
    "        y_true, y_pred,\n",
    "        labels=labels,\n",
    "        target_names=target_names,\n",
    "        digits=3,\n",
    "        zero_division=0\n",
    "    )\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 4) Confusion matrix\n",
    "# -----------------------------------------------------------\n",
    "print(\"\\nüîç CONFUSION MATRIX\")\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "# header row\n",
    "print(\"True\\\\Pred\", *[f\"{lbl}‚òÖ\" for lbl in labels], sep=\"  \")\n",
    "for i, true_lbl in enumerate(labels):\n",
    "    row_vals = \"  \".join(f\"{cm[i, j]:2d}\" for j in range(len(labels)))\n",
    "    print(f\"   {true_lbl}‚òÖ   {row_vals}\")\n",
    "\n",
    "diag    = np.trace(cm)\n",
    "tot     = cm.sum()\n",
    "print(f\"\\n   Correct predictions : {diag}/{tot} ({diag/tot:.1%})\")\n",
    "\n",
    "# most frequent confusions (off-diagonal)\n",
    "off_diag = [\n",
    "    (cm[i, j], labels[i], labels[j])\n",
    "    for i in range(len(labels)) for j in range(len(labels))\n",
    "    if i != j and cm[i, j] > 0\n",
    "]\n",
    "if off_diag:\n",
    "    off_diag.sort(reverse=True)\n",
    "    print(\"   Top confusions:\")\n",
    "    for count, t, p in off_diag[:3]:\n",
    "        print(f\"     {t}‚òÖ ‚Üí {p}‚òÖ : {count}√ó\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 5) Per-class hit rate\n",
    "# -----------------------------------------------------------\n",
    "print(\"\\nüé≠ PER-CLASS ACCURACY\")\n",
    "for lbl in labels:\n",
    "    mask = y_true == lbl\n",
    "    if mask.any():\n",
    "        class_acc = (y_pred[mask] == lbl).mean()\n",
    "        print(f\"   {lbl}‚òÖ : {class_acc:.1%} ({mask.sum()} samples)\")\n",
    "    else:\n",
    "        print(f\"   {lbl}‚òÖ : no samples in test set\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8479601c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç  DETAILED PREDICTION REVIEW\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Sample  1 | True: 1‚òÖ ‚Üí Pred: 3‚òÖ ‚ùå\n",
      "Confidence: 31.4% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "All classes: 1‚òÖ:25% 2‚òÖ:26% 3‚òÖ:31% 4‚òÖ:16% 5‚òÖ:2% \n",
      "\n",
      "================================================================================\n",
      "Sample  2 | True: 1‚òÖ ‚Üí Pred: 3‚òÖ ‚ùå\n",
      "Confidence: 35.2% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "All classes: 1‚òÖ:34% 2‚òÖ:15% 3‚òÖ:35% 4‚òÖ:14% 5‚òÖ:1% \n",
      "\n",
      "================================================================================\n",
      "Sample  3 | True: 1‚òÖ ‚Üí Pred: 3‚òÖ ‚ùå\n",
      "Confidence: 32.0% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "All classes: 1‚òÖ:26% 2‚òÖ:21% 3‚òÖ:32% 4‚òÖ:16% 5‚òÖ:5% \n",
      "\n",
      "================================================================================\n",
      "Sample  4 | True: 2‚òÖ ‚Üí Pred: 3‚òÖ ‚ùå\n",
      "Confidence: 33.6% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "All classes: 1‚òÖ:19% 2‚òÖ:21% 3‚òÖ:34% 4‚òÖ:17% 5‚òÖ:10% \n",
      "\n",
      "================================================================================\n",
      "Sample  5 | True: 2‚òÖ ‚Üí Pred: 3‚òÖ ‚ùå\n",
      "Confidence: 35.4% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "All classes: 1‚òÖ:29% 2‚òÖ:20% 3‚òÖ:35% 4‚òÖ:6% 5‚òÖ:9% \n",
      "\n",
      "================================================================================\n",
      "Sample  6 | True: 2‚òÖ ‚Üí Pred: 3‚òÖ ‚ùå\n",
      "Confidence: 29.9% ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "All classes: 1‚òÖ:16% 2‚òÖ:25% 3‚òÖ:30% 4‚òÖ:23% 5‚òÖ:6% \n",
      "\n",
      "================================================================================\n",
      "Sample  7 | True: 3‚òÖ ‚Üí Pred: 3‚òÖ ‚úÖ\n",
      "Confidence: 29.4% ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "All classes: 1‚òÖ:2% 2‚òÖ:17% 3‚òÖ:29% 4‚òÖ:27% 5‚òÖ:24% \n",
      "\n",
      "================================================================================\n",
      "Sample  8 | True: 3‚òÖ ‚Üí Pred: 3‚òÖ ‚úÖ\n",
      "Confidence: 32.4% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "All classes: 1‚òÖ:17% 2‚òÖ:16% 3‚òÖ:32% 4‚òÖ:31% 5‚òÖ:4% \n",
      "\n",
      "================================================================================\n",
      "Sample  9 | True: 3‚òÖ ‚Üí Pred: 3‚òÖ ‚úÖ\n",
      "Confidence: 34.4% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "All classes: 1‚òÖ:26% 2‚òÖ:15% 3‚òÖ:34% 4‚òÖ:14% 5‚òÖ:11% \n",
      "\n",
      "================================================================================\n",
      "Sample 10 | True: 4‚òÖ ‚Üí Pred: 3‚òÖ ‚ùå\n",
      "Confidence: 32.5% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "All classes: 1‚òÖ:2% 2‚òÖ:9% 3‚òÖ:33% 4‚òÖ:30% 5‚òÖ:27% \n",
      "\n",
      "================================================================================\n",
      "Sample 11 | True: 4‚òÖ ‚Üí Pred: 3‚òÖ ‚ùå\n",
      "Confidence: 33.3% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "All classes: 1‚òÖ:3% 2‚òÖ:20% 3‚òÖ:33% 4‚òÖ:30% 5‚òÖ:14% \n",
      "\n",
      "================================================================================\n",
      "Sample 12 | True: 4‚òÖ ‚Üí Pred: 3‚òÖ ‚ùå\n",
      "Confidence: 32.0% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "All classes: 1‚òÖ:8% 2‚òÖ:20% 3‚òÖ:32% 4‚òÖ:29% 5‚òÖ:11% \n",
      "\n",
      "================================================================================\n",
      "Sample 13 | True: 5‚òÖ ‚Üí Pred: 3‚òÖ ‚ùå\n",
      "Confidence: 33.2% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "All classes: 1‚òÖ:1% 2‚òÖ:9% 3‚òÖ:33% 4‚òÖ:27% 5‚òÖ:29% \n",
      "\n",
      "================================================================================\n",
      "Sample 14 | True: 5‚òÖ ‚Üí Pred: 3‚òÖ ‚ùå\n",
      "Confidence: 31.1% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "All classes: 1‚òÖ:1% 2‚òÖ:16% 3‚òÖ:31% 4‚òÖ:24% 5‚òÖ:28% \n",
      "\n",
      "================================================================================\n",
      "Sample 15 | True: 5‚òÖ ‚Üí Pred: 3‚òÖ ‚ùå\n",
      "Confidence: 31.6% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "All classes: 1‚òÖ:9% 2‚òÖ:25% 3‚òÖ:32% 4‚òÖ:30% 5‚òÖ:4% \n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 7) PER-REVIEW DIAGNOSTICS\n",
    "# =============================================================================\n",
    "import textwrap\n",
    "\n",
    "print(\"\\nüîç  DETAILED PREDICTION REVIEW\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i in range(len(y_true)):\n",
    "    true_r  = int(y_true[i])\n",
    "    pred_r  = int(y_pred[i])\n",
    "    correct = (true_r == pred_r)\n",
    "    status  = \"‚úÖ\" if correct else \"‚ùå\"\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"Sample {i+1:2d} | True: {true_r}‚òÖ ‚Üí Pred: {pred_r}‚òÖ {status}\")\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # Confidence bar (if we have probabilities)\n",
    "    # -----------------------------------------------------------\n",
    "    if confidence is not None:\n",
    "        conf = float(confidence[i])\n",
    "        bar  = \"‚ñà\" * int(conf * 20)\n",
    "        print(f\"Confidence: {conf:.1%} {bar}\")\n",
    "\n",
    "        # print full class probabilities\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            probs = y_proba[i]\n",
    "            print(\"All classes:\", end=\" \")\n",
    "            for idx, p in enumerate(probs):\n",
    "                star = idx + 1 if min(y_pred) == 0 else idx + 1  # labels already 1-5 after mapping\n",
    "                print(f\"{star}‚òÖ:{p:.0%}\", end=\" \")\n",
    "            print()\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # Show the review text when we loaded from CSV\n",
    "    # -----------------------------------------------------------\n",
    "    if sample_texts is not None:\n",
    "        print(\"-\" * 80)\n",
    "        snippet = sample_texts[i]\n",
    "        if len(snippet) > 400:\n",
    "            snippet = snippet[:400] + \" ‚Ä¶\"\n",
    "        print(textwrap.fill(snippet, width=76))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b4c09ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå FEHLERANALYSE\n",
      "==================================================\n",
      "Falsche Vorhersagen: 12/15\n",
      "\n",
      "Fehler-Muster:\n",
      "   1‚Üí4: 3x (Diff: 3 Sterne)\n",
      "   2‚Üí4: 3x (Diff: 2 Sterne)\n",
      "   3‚Üí4: 3x (Diff: 1 Sterne)\n",
      "   4‚Üí6: 1x (Diff: 2 Sterne)\n",
      "   5‚Üí4: 2x (Diff: 1 Sterne)\n",
      "\n",
      "√ò Abweichung bei Fehlern: 1.83 Sterne\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 8) FEHLERANALYSE\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n‚ùå FEHLERANALYSE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Finde falsche Vorhersagen\n",
    "wrong_indices = np.where(y_true != y_pred_orig)[0]\n",
    "wrong_count = len(wrong_indices)\n",
    "\n",
    "if wrong_count == 0:\n",
    "    print(\"üéâ Alle Vorhersagen waren korrekt!\")\n",
    "else:\n",
    "    print(f\"Falsche Vorhersagen: {wrong_count}/{len(y_true)}\")\n",
    "    \n",
    "    # Analysiere Fehler-Muster\n",
    "    error_patterns = {}\n",
    "    for idx in wrong_indices:\n",
    "        true_r = y_true[idx]\n",
    "        pred_r = y_pred_orig[idx]\n",
    "        pattern = f\"{true_r}‚Üí{pred_r}\"\n",
    "        error_patterns[pattern] = error_patterns.get(pattern, 0) + 1\n",
    "    \n",
    "    print(\"\\nFehler-Muster:\")\n",
    "    for pattern, count in sorted(error_patterns.items()):\n",
    "        true_r, pred_r = pattern.split('‚Üí')\n",
    "        diff = abs(int(true_r) - int(pred_r))\n",
    "        print(f\"   {pattern}: {count}x (Diff: {diff} Sterne)\")\n",
    "    \n",
    "    # Durchschnittliche Abweichung bei Fehlern\n",
    "    avg_error = np.mean([abs(y_true[i] - y_pred_orig[i]) for i in wrong_indices])\n",
    "    print(f\"\\n√ò Abweichung bei Fehlern: {avg_error:.2f} Sterne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba70a614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ CONFIDENCE-ANALYSE\n",
      "==================================================\n",
      "Durchschnittliche Confidence: 31.4%\n",
      "Niedrigste Confidence: 29.3%\n",
      "H√∂chste Confidence: 33.4%\n",
      "Confidence bei korrekten Vorhersagen: 31.4%\n",
      "Confidence bei falschen Vorhersagen: 31.4%\n",
      "\n",
      "Niedrigste Confidence F√§lle:\n",
      "   Sample 4: 2‚≠ê‚Üí4‚≠ê ‚ùå (29.3%)\n",
      "   Sample 7: 3‚≠ê‚Üí4‚≠ê ‚ùå (30.5%)\n",
      "   Sample 15: 5‚≠ê‚Üí4‚≠ê ‚ùå (30.5%)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 9) CONFIDENCE-ANALYSE\n",
    "# =============================================================================\n",
    "\n",
    "if confidence is not None:\n",
    "    print(f\"\\nüéØ CONFIDENCE-ANALYSE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    avg_conf = confidence.mean()\n",
    "    min_conf = confidence.min()\n",
    "    max_conf = confidence.max()\n",
    "    \n",
    "    print(f\"Durchschnittliche Confidence: {avg_conf:.1%}\")\n",
    "    print(f\"Niedrigste Confidence: {min_conf:.1%}\")\n",
    "    print(f\"H√∂chste Confidence: {max_conf:.1%}\")\n",
    "    \n",
    "    # Confidence vs. Korrektheit\n",
    "    correct_mask = (y_true == y_pred_orig)\n",
    "    if np.any(correct_mask):\n",
    "        avg_conf_correct = confidence[correct_mask].mean()\n",
    "        print(f\"Confidence bei korrekten Vorhersagen: {avg_conf_correct:.1%}\")\n",
    "    \n",
    "    if np.any(~correct_mask):\n",
    "        avg_conf_wrong = confidence[~correct_mask].mean()\n",
    "        print(f\"Confidence bei falschen Vorhersagen: {avg_conf_wrong:.1%}\")\n",
    "    \n",
    "    # Niedrigste Confidence F√§lle\n",
    "    low_conf_indices = np.argsort(confidence)[:3]\n",
    "    print(f\"\\nNiedrigste Confidence F√§lle:\")\n",
    "    for idx in low_conf_indices:\n",
    "        true_r, pred_r = y_true[idx], y_pred_orig[idx]\n",
    "        conf = confidence[idx]\n",
    "        status = \"‚úÖ\" if true_r == pred_r else \"‚ùå\"\n",
    "        print(f\"   Sample {idx+1}: {true_r}‚≠ê‚Üí{pred_r}‚≠ê {status} ({conf:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12beaa95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéÆ BEISPIEL: CUSTOM TEXT TEST\n",
      "==================================================\n",
      "testtst <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 5 stored elements and shape (1, 5010)>\n",
      "  Coords\tValues\n",
      "  (0, 98)\t0.4261538241554763\n",
      "  (0, 306)\t0.40489382633340476\n",
      "  (0, 3164)\t0.24615886958176456\n",
      "  (0, 3165)\t0.702660449165133\n",
      "  (0, 3243)\t0.31643010548941036\n",
      "üîÆ Vorhersage mit Wahrscheinlichkeiten:\n",
      "\n",
      "Test 1: 2‚≠ê (Confidence: 41.8%)\n",
      "Text: This product is amazing! Best purchase ever!\n",
      "testtst <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 6 stored elements and shape (1, 5010)>\n",
      "  Coords\tValues\n",
      "  (0, 392)\t0.49506702537777625\n",
      "  (0, 422)\t0.2524125041938558\n",
      "  (0, 1887)\t0.3777895866716374\n",
      "  (0, 3265)\t0.2086605463212705\n",
      "  (0, 4418)\t0.38568962989905486\n",
      "  (0, 4423)\t0.5968047269500295\n",
      "üîÆ Vorhersage mit Wahrscheinlichkeiten:\n",
      "\n",
      "Test 2: 3‚≠ê (Confidence: 42.7%)\n",
      "Text: Terrible quality, broke immediately. Don't buy!\n",
      "testtst <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 3 stored elements and shape (1, 5010)>\n",
      "  Coords\tValues\n",
      "  (0, 2169)\t0.5750519475388014\n",
      "  (0, 2655)\t0.5769974564406569\n",
      "  (0, 4021)\t0.5799906834534878\n",
      "üîÆ Vorhersage mit Wahrscheinlichkeiten:\n",
      "\n",
      "Test 3: 2‚≠ê (Confidence: 42.8%)\n",
      "Text: It's okay, nothing special but does the job.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 12) INTERAKTIVER TEST\n",
    "# =============================================================================\n",
    "\n",
    "def test_custom_text(text_input):\n",
    "    \"\"\"Teste einen einzelnen Text - KORRIGIERTE VERSION\"\"\"\n",
    "    try:\n",
    "        # Feature-Extraktion basierend auf Modell-Typ\n",
    "        model_features = mdl_dict.get(\"feature_combination\", \"combined\")\n",
    "        \n",
    "        if model_features == \"tfidf_only\":\n",
    "            X_custom = vectorizer.transform([text_input])\n",
    "        elif model_features == \"numerical_only\":\n",
    "            print(\"‚ö†Ô∏è Custom Text Test mit 'numerical_only' nicht m√∂glich (keine Textfeatures)\")\n",
    "            return None\n",
    "        else:  # combined - hier war der Hauptfehler\n",
    "            X_tfidf = vectorizer.transform([text_input])\n",
    "            \n",
    "            X_custom = X_tfidf\n",
    "        \n",
    "        pred_enc = clf.predict(X_custom)[0]\n",
    "        pred_orig = label_encoder.inverse_transform([pred_enc])[0]\n",
    "        \n",
    "        result = {\n",
    "            'prediction': pred_orig,\n",
    "            'confidence': None\n",
    "        }\n",
    "        \n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            print(\"üîÆ Vorhersage mit Wahrscheinlichkeiten:\")\n",
    "            proba = clf.predict_proba(X_custom)[0]\n",
    "            result['confidence'] = proba.max()\n",
    "            result['all_probabilities'] = {\n",
    "                label_encoder.inverse_transform([i])[0]: prob \n",
    "                for i, prob in enumerate(proba)\n",
    "            }\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fehler beim Custom Test: {e}\")\n",
    "        return None\n",
    "\n",
    "# Beispiel f√ºr Custom Test (Automatisch)\n",
    "print(f\"\\nüéÆ BEISPIEL: CUSTOM TEXT TEST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "test_texts = [\n",
    "    \"This product is amazing! Best purchase ever!\",\n",
    "    \"Terrible quality, broke immediately. Don't buy!\",\n",
    "    \"It's okay, nothing special but does the job.\"\n",
    "]\n",
    "\n",
    "for i, test_text in enumerate(test_texts):\n",
    "    result = test_custom_text(test_text)\n",
    "    if result:\n",
    "        print(f\"\\nTest {i+1}: {result['prediction']}‚≠ê\", end=\"\")\n",
    "        if result['confidence']:\n",
    "            print(f\" (Confidence: {result['confidence']:.1%})\")\n",
    "        else:\n",
    "            print()\n",
    "        print(f\"Text: {test_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "48c52109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üéÆ INTERACTIVE MODE - Teste eigene Reviews!\n",
      "(Gib 'quit' ein zum Beenden)\n",
      "============================================================\n",
      "\n",
      "üîÆ ERGEBNIS F√úR EINGABE #1:\n",
      "--------------------------------------------------\n",
      "Eingabe: geniales product\n",
      "Vorhersage: 2‚≠ê\n",
      "Confidence: 45.9% [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë]\n",
      "\n",
      "üìä WAHRSCHEINLICHKEITSVERTEILUNG:\n",
      "--------------------------------------------------\n",
      "Rating   Wahrscheinlichkeit Visualisierung\n",
      "--------------------------------------------------\n",
      "1‚≠ê       14.2%             ‚ñà‚ñà‚ñà\n",
      "2‚≠ê       45.9%             ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "3‚≠ê       32.5%             ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "4‚≠ê       5.7%             ‚ñà\n",
      "5‚≠ê       1.7%             \n",
      "--------------------------------------------------\n",
      "\n",
      "üîÆ ERGEBNIS F√úR EINGABE #2:\n",
      "--------------------------------------------------\n",
      "Eingabe: ich mag das product sehr und w√ºrde es wieder kaufen\n",
      "Vorhersage: 2‚≠ê\n",
      "Confidence: 45.9% [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë]\n",
      "\n",
      "üìä WAHRSCHEINLICHKEITSVERTEILUNG:\n",
      "--------------------------------------------------\n",
      "Rating   Wahrscheinlichkeit Visualisierung\n",
      "--------------------------------------------------\n",
      "1‚≠ê       14.2%             ‚ñà‚ñà‚ñà\n",
      "2‚≠ê       45.9%             ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "3‚≠ê       32.5%             ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "4‚≠ê       5.7%             ‚ñà\n",
      "5‚≠ê       1.7%             \n",
      "--------------------------------------------------\n",
      "\n",
      "üîÆ ERGEBNIS F√úR EINGABE #3:\n",
      "--------------------------------------------------\n",
      "Eingabe: sehr gut sehr gut sehr gut\n",
      "Vorhersage: 2‚≠ê\n",
      "Confidence: 44.9% [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë]\n",
      "\n",
      "üìä WAHRSCHEINLICHKEITSVERTEILUNG:\n",
      "--------------------------------------------------\n",
      "Rating   Wahrscheinlichkeit Visualisierung\n",
      "--------------------------------------------------\n",
      "1‚≠ê       11.0%             ‚ñà‚ñà\n",
      "2‚≠ê       44.9%             ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "3‚≠ê       36.2%             ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "4‚≠ê       6.3%             ‚ñà\n",
      "5‚≠ê       1.6%             \n",
      "--------------------------------------------------\n",
      "üëã Interaktiver Test beendet!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 13) INTERAKTIVER EINGABE-TEST \n",
    "# =============================================================================\n",
    "\n",
    "def interactive_prediction():\n",
    "    \"\"\"Interaktive Vorhersage f√ºr eigene Texte - NEUE VERSION\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üéÆ INTERACTIVE MODE - Teste eigene Reviews!\")\n",
    "    print(\"(Gib 'quit' ein zum Beenden)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    counter = 1\n",
    "    while True:\n",
    "        try:\n",
    "            user_text = input(f\"\\n[{counter}] üìù Gib einen Review-Text ein: \").strip()\n",
    "            \n",
    "            if user_text.lower() in ['quit', 'exit', 'q', '']:\n",
    "                print(\"üëã Interaktiver Test beendet!\")\n",
    "                break\n",
    "                \n",
    "            if not user_text:\n",
    "                print(\"‚ùå Bitte gib einen Text ein!\")\n",
    "                continue\n",
    "            \n",
    "            # Vorhersage mit korrigierter Funktion\n",
    "            result = test_custom_text(user_text)\n",
    "            \n",
    "            if result:\n",
    "                print(f\"\\nüîÆ ERGEBNIS F√úR EINGABE #{counter}:\")\n",
    "                print(\"-\" * 50)\n",
    "                print(f\"Eingabe: {user_text}\")\n",
    "                print(f\"Vorhersage: {result['prediction']}‚≠ê\")\n",
    "                \n",
    "                if result['confidence']:\n",
    "                    conf_bar = \"‚ñà\" * int(result['confidence'] * 20) + \"‚ñë\" * (20 - int(result['confidence'] * 20))\n",
    "                    print(f\"Confidence: {result['confidence']:.1%} [{conf_bar}]\")\n",
    "                \n",
    "                if 'all_probabilities' in result:\n",
    "                    print(f\"\\nüìä WAHRSCHEINLICHKEITSVERTEILUNG:\")\n",
    "                    print(\"-\" * 50)\n",
    "                    print(f\"{'Rating':<8} {'Wahrscheinlichkeit':<15} {'Visualisierung'}\")\n",
    "                    print(\"-\" * 50)\n",
    "                    \n",
    "                    for rating in sorted(result['all_probabilities'].keys()):\n",
    "                        prob = result['all_probabilities'][rating]\n",
    "                        bar = \"‚ñà\" * int(prob * 25)\n",
    "                        print(f\"{rating}‚≠ê{'':<6} {prob:.1%}{'':<12} {bar}\")\n",
    "                \n",
    "                print(\"-\" * 50)\n",
    "            else:\n",
    "                print(\"‚ùå Fehler bei der Vorhersage\")\n",
    "            \n",
    "            counter += 1\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nüëã Abgebrochen durch Benutzer!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Fehler: {e}\")\n",
    "\n",
    "# Starte den interaktiven Modus\n",
    "interactive_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0f29ae49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ SYSTEMATISCHER TEST MIT VERBESSERTEN BEISPIELEN\n",
      "======================================================================\n",
      "\n",
      "‚≠ê ERWARTETE 5 STERNE:\n",
      "--------------------------------------------------\n",
      "‚ùå Beispiel 1: 2‚≠ê (Conf: 41.2%)\n",
      "   Text: Absolutely amazing product! Exceeded all my expectations. Fast shipping, perfect...\n",
      "   Verteilung: 1‚≠ê:8% 2‚≠ê:41% 3‚≠ê:35% 4‚≠ê:11% 5‚≠ê:4% \n",
      "\n",
      "‚ùå Beispiel 2: 3‚≠ê (Conf: 42.1%)\n",
      "   Text: Outstanding quality for the price! The item arrived quickly and was packaged ver...\n",
      "   Verteilung: 1‚≠ê:6% 2‚≠ê:41% 3‚≠ê:42% 4‚≠ê:9% 5‚≠ê:2% \n",
      "\n",
      "‚ùå Beispiel 3: 2‚≠ê (Conf: 44.0%)\n",
      "   Text: Perfect purchase! This product is fantastic, great value for money. The seller w...\n",
      "   Verteilung: 1‚≠ê:12% 2‚≠ê:44% 3‚≠ê:33% 4‚≠ê:8% 5‚≠ê:3% \n",
      "\n",
      "‚ùå Beispiel 4: 3‚≠ê (Conf: 48.1%)\n",
      "   Text: Exceptional item! Top quality materials, exactly what I needed. The seller commu...\n",
      "   Verteilung: 1‚≠ê:3% 2‚≠ê:34% 3‚≠ê:48% 4‚≠ê:12% 5‚≠ê:2% \n",
      "\n",
      "\n",
      "‚≠ê ERWARTETE 4 STERNE:\n",
      "--------------------------------------------------\n",
      "‚ùå Beispiel 1: 2‚≠ê (Conf: 48.9%)\n",
      "   Text: Great product overall! Good quality and works as expected. Shipping took a bit l...\n",
      "   Verteilung: 1‚≠ê:17% 2‚≠ê:49% 3‚≠ê:29% 4‚≠ê:5% 5‚≠ê:1% \n",
      "\n",
      "‚ùå Beispiel 2: 3‚≠ê (Conf: 45.5%)\n",
      "   Text: Very satisfied with this purchase. The item is well made and functional. Only mi...\n",
      "   Verteilung: 1‚≠ê:5% 2‚≠ê:40% 3‚≠ê:45% 4‚≠ê:8% 5‚≠ê:1% \n",
      "\n",
      "‚ùå Beispiel 3: 2‚≠ê (Conf: 42.7%)\n",
      "   Text: Good quality product at a reasonable price. Delivery was on time and the item ma...\n",
      "   Verteilung: 1‚≠ê:11% 2‚≠ê:43% 3‚≠ê:33% 4‚≠ê:9% 5‚≠ê:3% \n",
      "\n",
      "‚ùå Beispiel 4: 2‚≠ê (Conf: 47.7%)\n",
      "   Text: Happy with this buy! The product works well and looks good. Installation was str...\n",
      "   Verteilung: 1‚≠ê:12% 2‚≠ê:48% 3‚≠ê:33% 4‚≠ê:5% 5‚≠ê:1% \n",
      "\n",
      "\n",
      "‚≠ê ERWARTETE 3 STERNE:\n",
      "--------------------------------------------------\n",
      "‚ùå Beispiel 1: 2‚≠ê (Conf: 43.4%)\n",
      "   Text: Average product. It does what it's supposed to do but nothing special. Quality i...\n",
      "   Verteilung: 1‚≠ê:9% 2‚≠ê:43% 3‚≠ê:37% 4‚≠ê:9% 5‚≠ê:2% \n",
      "\n",
      "‚ùå Beispiel 2: 2‚≠ê (Conf: 46.8%)\n",
      "   Text: Mixed feelings about this purchase. Some aspects are good, others could be impro...\n",
      "   Verteilung: 1‚≠ê:10% 2‚≠ê:47% 3‚≠ê:36% 4‚≠ê:6% 5‚≠ê:1% \n",
      "\n",
      "‚ùå Beispiel 3: 2‚≠ê (Conf: 46.0%)\n",
      "   Text: It's an okay product. Not bad but not great either. Quality is acceptable and it...\n",
      "   Verteilung: 1‚≠ê:15% 2‚≠ê:46% 3‚≠ê:30% 4‚≠ê:7% 5‚≠ê:2% \n",
      "\n",
      "‚ùå Beispiel 4: 2‚≠ê (Conf: 46.4%)\n",
      "   Text: Mediocre item. Gets the job done but I expected better quality. Shipping was fin...\n",
      "   Verteilung: 1‚≠ê:17% 2‚≠ê:46% 3‚≠ê:31% 4‚≠ê:4% 5‚≠ê:1% \n",
      "\n",
      "\n",
      "‚≠ê ERWARTETE 2 STERNE:\n",
      "--------------------------------------------------\n",
      "‚úÖ Beispiel 1: 2‚≠ê (Conf: 52.2%)\n",
      "   Text: Disappointed with this purchase. The quality is poor and it feels flimsy. Only p...\n",
      "\n",
      "‚úÖ Beispiel 2: 2‚≠ê (Conf: 41.8%)\n",
      "   Text: Not what I expected. The item looks different from the photos and feels cheap. I...\n",
      "\n",
      "‚úÖ Beispiel 3: 2‚≠ê (Conf: 48.3%)\n",
      "   Text: Poor quality product. Had issues right after opening. The material feels very ch...\n",
      "\n",
      "‚úÖ Beispiel 4: 2‚≠ê (Conf: 45.3%)\n",
      "   Text: Unsatisfied with this buy. The product is smaller than expected and build qualit...\n",
      "\n",
      "\n",
      "‚≠ê ERWARTETE 1 STERNE:\n",
      "--------------------------------------------------\n",
      "‚ùå Beispiel 1: 3‚≠ê (Conf: 42.6%)\n",
      "   Text: Terrible product! Completely useless and broke immediately after opening. Worst ...\n",
      "   Verteilung: 1‚≠ê:6% 2‚≠ê:41% 3‚≠ê:43% 4‚≠ê:9% 5‚≠ê:2% \n",
      "\n",
      "‚ùå Beispiel 2: 2‚≠ê (Conf: 48.6%)\n",
      "   Text: Absolute waste of money! The item is nothing like described, extremely poor qual...\n",
      "   Verteilung: 1‚≠ê:27% 2‚≠ê:49% 3‚≠ê:21% 4‚≠ê:2% 5‚≠ê:1% \n",
      "\n",
      "‚ùå Beispiel 3: 3‚≠ê (Conf: 45.2%)\n",
      "   Text: Horrible experience! Product is defective and unusable. Seller refuses to help o...\n",
      "   Verteilung: 1‚≠ê:6% 2‚≠ê:40% 3‚≠ê:45% 4‚≠ê:7% 5‚≠ê:1% \n",
      "\n",
      "‚ùå Beispiel 4: 2‚≠ê (Conf: 52.4%)\n",
      "   Text: Do not buy this! Completely broken on arrival, terrible packaging. Item looks no...\n",
      "   Verteilung: 1‚≠ê:8% 2‚≠ê:52% 3‚≠ê:33% 4‚≠ê:5% 5‚≠ê:1% \n",
      "\n",
      "\n",
      "üìä GESAMTERGEBNIS:\n",
      "Korrekte Vorhersagen: 4/20 (20.0%)\n",
      "\n",
      "üîç WORT-ANALYSE:\n",
      "Teste einzelne charakteristische W√∂rter/Phrasen...\n",
      "\n",
      "Wort/Phrase ‚Üí Vorhersage:\n",
      "‚ùå 'amazing' ‚Üí 2‚≠ê (erwartet: 5‚≠ê)\n",
      "‚ùå 'excellent' ‚Üí 3‚≠ê (erwartet: 5‚≠ê)\n",
      "‚ùå 'perfect' ‚Üí 3‚≠ê (erwartet: 5‚≠ê)\n",
      "‚ùå 'outstanding' ‚Üí 3‚≠ê (erwartet: 5‚≠ê)\n",
      "‚ùå 'terrible' ‚Üí 3‚≠ê (erwartet: 1‚≠ê)\n",
      "‚ùå 'horrible' ‚Üí 2‚≠ê (erwartet: 1‚≠ê)\n",
      "‚ùå 'waste of money' ‚Üí 2‚≠ê (erwartet: 1‚≠ê)\n",
      "‚ùå 'broke immediately' ‚Üí 3‚≠ê (erwartet: 1‚≠ê)\n",
      "‚ùå 'good quality' ‚Üí 2‚≠ê (erwartet: 4‚≠ê)\n",
      "‚ùå 'works well' ‚Üí 2‚≠ê (erwartet: 4‚≠ê)\n",
      "‚ùå 'okay' ‚Üí 2‚≠ê (erwartet: 3‚≠ê)\n",
      "‚ùå 'average' ‚Üí 2‚≠ê (erwartet: 3‚≠ê)\n",
      "‚úÖ 'poor quality' ‚Üí 2‚≠ê (erwartet: 2‚≠ê)\n",
      "‚úÖ 'disappointed' ‚Üí 2‚≠ê (erwartet: 2‚≠ê)\n"
     ]
    }
   ],
   "source": [
    "# Verbesserte Test-Beispiele f√ºr verschiedene Sterne-Kategorien\n",
    "\n",
    "# 5 STERNE - Sehr positive Reviews\n",
    "five_star_examples = [\n",
    "    \"Absolutely amazing product! Exceeded all my expectations. Fast shipping, perfect quality, exactly as described. Will definitely order again from this seller. Highly recommend to everyone!\",\n",
    "    \"Outstanding quality for the price! The item arrived quickly and was packaged very well. Works perfectly and looks even better than in the photos. Customer service was excellent too.\",\n",
    "    \"Perfect purchase! This product is fantastic, great value for money. The seller was responsive and helpful. Shipping was super fast. Could not be happier with this buy!\",\n",
    "    \"Exceptional item! Top quality materials, exactly what I needed. The seller communicated well and shipped immediately. This exceeded my expectations in every way possible.\"\n",
    "]\n",
    "\n",
    "# 4 STERNE - Positive Reviews mit kleinen Einschr√§nkungen\n",
    "four_star_examples = [\n",
    "    \"Great product overall! Good quality and works as expected. Shipping took a bit longer than anticipated but worth the wait. Would recommend this to others.\",\n",
    "    \"Very satisfied with this purchase. The item is well made and functional. Only minor issue was the packaging could have been better, but the product itself is excellent.\",\n",
    "    \"Good quality product at a reasonable price. Delivery was on time and the item matches the description. Small scratches on arrival but nothing major.\",\n",
    "    \"Happy with this buy! The product works well and looks good. Installation was straightforward. Only wish it came with better instructions.\"\n",
    "]\n",
    "\n",
    "# 3 STERNE - Neutrale/gemischte Reviews\n",
    "three_star_examples = [\n",
    "    \"Average product. It does what it's supposed to do but nothing special. Quality is okay for the price. Shipping was standard.\",\n",
    "    \"Mixed feelings about this purchase. Some aspects are good, others could be improved. It works but feels a bit cheap. Decent value overall.\",\n",
    "    \"It's an okay product. Not bad but not great either. Quality is acceptable and it serves its purpose. Would consider other options next time.\",\n",
    "    \"Mediocre item. Gets the job done but I expected better quality. Shipping was fine. It's functional but not impressive.\"\n",
    "]\n",
    "\n",
    "# 2 STERNE - Negative Reviews mit einigen positiven Aspekten\n",
    "two_star_examples = [\n",
    "    \"Disappointed with this purchase. The quality is poor and it feels flimsy. Only positive is that shipping was fast. Would not buy again.\",\n",
    "    \"Not what I expected. The item looks different from the photos and feels cheap. It works but barely. Customer service was unhelpful.\",\n",
    "    \"Poor quality product. Had issues right after opening. The material feels very cheap. Only reason for 2 stars is that it arrived on time.\",\n",
    "    \"Unsatisfied with this buy. The product is smaller than expected and build quality is questionable. Shipping was okay but that's about it.\"\n",
    "]\n",
    "\n",
    "# 1 STERN - Sehr negative Reviews\n",
    "one_star_examples = [\n",
    "    \"Terrible product! Completely useless and broke immediately after opening. Worst purchase ever. Poor quality, misleading description. Avoid this seller!\",\n",
    "    \"Absolute waste of money! The item is nothing like described, extremely poor quality. Took forever to arrive and was damaged. Complete scam!\",\n",
    "    \"Horrible experience! Product is defective and unusable. Seller refuses to help or refund. Cheap plastic junk that falls apart instantly.\",\n",
    "    \"Do not buy this! Completely broken on arrival, terrible packaging. Item looks nothing like the photos. Seller is unresponsive. Total disaster!\"\n",
    "]\n",
    "\n",
    "# Alle Beispiele kombinieren f√ºr systematischen Test\n",
    "all_test_examples = {\n",
    "    5: five_star_examples,\n",
    "    4: four_star_examples, \n",
    "    3: three_star_examples,\n",
    "    2: two_star_examples,\n",
    "    1: one_star_examples\n",
    "}\n",
    "\n",
    "print(\"üß™ SYSTEMATISCHER TEST MIT VERBESSERTEN BEISPIELEN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "total_correct = 0\n",
    "total_tests = 0\n",
    "\n",
    "for expected_stars, examples in all_test_examples.items():\n",
    "    print(f\"\\n‚≠ê ERWARTETE {expected_stars} STERNE:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for i, text in enumerate(examples, 1):\n",
    "        result = test_custom_text(text)\n",
    "        if result:\n",
    "            predicted = result['prediction']\n",
    "            confidence = result.get('confidence', 0)\n",
    "            is_correct = predicted == expected_stars\n",
    "            status = \"‚úÖ\" if is_correct else \"‚ùå\"\n",
    "            \n",
    "            total_tests += 1\n",
    "            if is_correct:\n",
    "                total_correct += 1\n",
    "            \n",
    "            print(f\"{status} Beispiel {i}: {predicted}‚≠ê (Conf: {confidence:.1%})\")\n",
    "            print(f\"   Text: {text[:80]}{'...' if len(text) > 80 else ''}\")\n",
    "            \n",
    "            # Zeige Wahrscheinlichkeitsverteilung bei falschen Vorhersagen\n",
    "            if not is_correct and 'all_probabilities' in result:\n",
    "                print(\"   Verteilung:\", end=\" \")\n",
    "                for rating in sorted(result['all_probabilities'].keys()):\n",
    "                    prob = result['all_probabilities'][rating]\n",
    "                    print(f\"{rating}‚≠ê:{prob:.0%}\", end=\" \")\n",
    "                print()\n",
    "        print()\n",
    "\n",
    "print(f\"\\nüìä GESAMTERGEBNIS:\")\n",
    "print(f\"Korrekte Vorhersagen: {total_correct}/{total_tests} ({total_correct/total_tests*100:.1f}%)\")\n",
    "\n",
    "# Zus√§tzliche Analyse: Welche W√∂rter/Phrasen f√ºhren zu welchen Bewertungen?\n",
    "print(f\"\\nüîç WORT-ANALYSE:\")\n",
    "print(\"Teste einzelne charakteristische W√∂rter/Phrasen...\")\n",
    "\n",
    "word_tests = {\n",
    "    \"amazing\": 5,\n",
    "    \"excellent\": 5, \n",
    "    \"perfect\": 5,\n",
    "    \"outstanding\": 5,\n",
    "    \"terrible\": 1,\n",
    "    \"horrible\": 1,\n",
    "    \"waste of money\": 1,\n",
    "    \"broke immediately\": 1,\n",
    "    \"good quality\": 4,\n",
    "    \"works well\": 4,\n",
    "    \"okay\": 3,\n",
    "    \"average\": 3,\n",
    "    \"poor quality\": 2,\n",
    "    \"disappointed\": 2\n",
    "}\n",
    "\n",
    "print(\"\\nWort/Phrase ‚Üí Vorhersage:\")\n",
    "for phrase, expected in word_tests.items():\n",
    "    result = test_custom_text(phrase)\n",
    "    if result:\n",
    "        predicted = result['prediction']\n",
    "        status = \"‚úÖ\" if predicted == expected else \"‚ùå\"\n",
    "        print(f\"{status} '{phrase}' ‚Üí {predicted}‚≠ê (erwartet: {expected}‚≠ê)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5bc16a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç DETAILLIERTE MODELL-DIAGNOSE\n",
      "============================================================\n",
      "1Ô∏è‚É£ MODELL-INFORMATIONEN:\n",
      "------------------------------\n",
      "Modell-Typ: StackingClassifier\n",
      "Modell-Name: Optimized Stacking\n",
      "Feature-Kombination: combined\n",
      "\n",
      "2Ô∏è‚É£ LABEL-ENCODING:\n",
      "------------------------------\n",
      "Original Classes: [1 2 3 4 5]\n",
      "Mapping:\n",
      "  1 (original) ‚Üí 0 (encoded)\n",
      "  2 (original) ‚Üí 1 (encoded)\n",
      "  3 (original) ‚Üí 2 (encoded)\n",
      "  4 (original) ‚Üí 3 (encoded)\n",
      "  5 (original) ‚Üí 4 (encoded)\n",
      "\n",
      "3Ô∏è‚É£ VECTORIZER-INFO:\n",
      "------------------------------\n",
      "Vectorizer-Typ: TfidfVectorizer\n",
      "Feature-Count: 5,010\n",
      "Max Features: 5010\n",
      "\n",
      "W√∂rter im Vokabular:\n",
      "  'amazing': ‚úÖ\n",
      "  'terrible': ‚úÖ\n",
      "  'good': ‚úÖ\n",
      "  'bad': ‚úÖ\n",
      "  'excellent': ‚úÖ\n",
      "\n",
      "4Ô∏è‚É£ FEATURE-MATRIX ANALYSE:\n",
      "------------------------------\n",
      "\n",
      "Phrase: 'amazing'\n",
      "  Sparse Matrix Shape: (1, 5010)\n",
      "  Non-zero Features: 1\n",
      "  Aktivierte Features: [('amazing', np.float64(1.0))]\n",
      "\n",
      "Phrase: 'terrible'\n",
      "  Sparse Matrix Shape: (1, 5010)\n",
      "  Non-zero Features: 1\n",
      "  Aktivierte Features: [('terrible', np.float64(1.0))]\n",
      "\n",
      "Phrase: 'good quality'\n",
      "  Sparse Matrix Shape: (1, 5010)\n",
      "  Non-zero Features: 3\n",
      "  Aktivierte Features: [('good', np.float64(0.43865844818213345)), ('good quality', np.float64(0.7732348367593327)), ('quality', np.float64(0.4579155523240181))]\n",
      "\n",
      "Phrase: 'poor quality'\n",
      "  Sparse Matrix Shape: (1, 5010)\n",
      "  Non-zero Features: 3\n",
      "  Aktivierte Features: [('poor', np.float64(0.5936373569943055)), ('poor quality', np.float64(0.7079998833738731)), ('quality', np.float64(0.3825321601165025))]\n",
      "\n",
      "5Ô∏è‚É£ VORHERSAGE-VERTEILUNG:\n",
      "------------------------------\n",
      "Vorhersage-Verteilung f√ºr Test-Texte:\n",
      "  2‚≠ê: 10/14 (71.4%) ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  3‚≠ê:  4/14 (28.6%) ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "6Ô∏è‚É£ WAHRSCHEINLICHKEITS-ANALYSE:\n",
      "------------------------------\n",
      "\n",
      "Text: 'amazing excellent perfect outstanding' (5‚≠ê erwartet)\n",
      "Vorhersage: 3‚≠ê\n",
      "Wahrscheinlichkeiten:\n",
      "  1‚≠ê: 0.053\n",
      "  2‚≠ê: 0.352\n",
      "  3‚≠ê: 0.503\n",
      "  4‚≠ê: 0.079\n",
      "  5‚≠ê: 0.013\n",
      "\n",
      "Text: 'terrible horrible awful waste broken' (1‚≠ê erwartet)\n",
      "Vorhersage: 2‚≠ê\n",
      "Wahrscheinlichkeiten:\n",
      "  1‚≠ê: 0.192\n",
      "  2‚≠ê: 0.509\n",
      "  3‚≠ê: 0.260\n",
      "  4‚≠ê: 0.031\n",
      "  5‚≠ê: 0.008\n",
      "\n",
      "7Ô∏è‚É£ MODELL-PARAMETER:\n",
      "------------------------------\n",
      "\n",
      "8Ô∏è‚É£ TRAINING-METRIKEN:\n",
      "------------------------------\n",
      "  test_accuracy: 0.6036429872495446\n",
      "  macro_f1: 0.44259819100400877\n",
      "  best_params: {}\n",
      "  feature_combination: combined\n",
      "\n",
      "9Ô∏è‚É£ DIAGNOSE-SCHLUSSFOLGERUNGEN:\n",
      "------------------------------\n",
      "\n",
      "üö® GEFUNDENE PROBLEME:\n",
      "  ‚ùå Modell vorhersagt nur 2-3 Sterne (bias Problem)\n",
      "  ‚ùå Kann extreme Bewertungen (1‚≠ê, 5‚≠ê) nicht erkennen\n",
      "  ‚ùå Label-Encoder Problem - falsche Klassen\n",
      "\n",
      "üí° L√ñSUNGSVORSCHL√ÑGE:\n",
      "  1. Modell komplett neu trainieren\n",
      "  2. Andere Algorithmen testen (Random Forest, XGBoost)\n",
      "  3. Hyperparameter-Tuning verbessern\n",
      "  4. Datenqualit√§t pr√ºfen (sind die Labels korrekt?)\n",
      "  5. Feature-Engineering √ºberdenken\n",
      "  6. Class Imbalance behandeln (SMOTE, Class Weights)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MODELL-DIAGNOSE - Was l√§uft schief?\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üîç DETAILLIERTE MODELL-DIAGNOSE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Modell-Informationen pr√ºfen\n",
    "print(\"1Ô∏è‚É£ MODELL-INFORMATIONEN:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Modell-Typ: {type(clf).__name__}\")\n",
    "print(f\"Modell-Name: {model_name}\")\n",
    "print(f\"Feature-Kombination: {mdl_dict.get('feature_combination', 'unknown')}\")\n",
    "\n",
    "# 2. Label-Encoder pr√ºfen\n",
    "print(f\"\\n2Ô∏è‚É£ LABEL-ENCODING:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Original Classes: {label_encoder.classes_}\")\n",
    "print(\"Mapping:\")\n",
    "for i, orig_label in enumerate(label_encoder.classes_):\n",
    "    print(f\"  {orig_label} (original) ‚Üí {i} (encoded)\")\n",
    "\n",
    "# 3. Vectorizer pr√ºfen\n",
    "print(f\"\\n3Ô∏è‚É£ VECTORIZER-INFO:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Vectorizer-Typ: {type(vectorizer).__name__}\")\n",
    "print(f\"Feature-Count: {len(vectorizer.get_feature_names_out()):,}\")\n",
    "print(f\"Max Features: {getattr(vectorizer, 'max_features', 'unlimited')}\")\n",
    "\n",
    "# Test einzelner W√∂rter im Vokabular\n",
    "test_words = ['amazing', 'terrible', 'good', 'bad', 'excellent']\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "print(f\"\\nW√∂rter im Vokabular:\")\n",
    "for word in test_words:\n",
    "    in_vocab = word in vocab\n",
    "    print(f\"  '{word}': {'‚úÖ' if in_vocab else '‚ùå'}\")\n",
    "\n",
    "# 4. Feature-Matrix f√ºr Test-W√∂rter analysieren\n",
    "print(f\"\\n4Ô∏è‚É£ FEATURE-MATRIX ANALYSE:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "test_phrases = ['amazing', 'terrible', 'good quality', 'poor quality']\n",
    "for phrase in test_phrases:\n",
    "    X_test = vectorizer.transform([phrase])\n",
    "    print(f\"\\nPhrase: '{phrase}'\")\n",
    "    print(f\"  Sparse Matrix Shape: {X_test.shape}\")\n",
    "    print(f\"  Non-zero Features: {X_test.nnz}\")\n",
    "    \n",
    "    # Zeige die aktivierten Features\n",
    "    if X_test.nnz > 0:\n",
    "        feature_indices = X_test.nonzero()[1]\n",
    "        feature_names = vocab[feature_indices]\n",
    "        feature_values = X_test.data\n",
    "        print(f\"  Aktivierte Features: {list(zip(feature_names, feature_values))[:5]}\")\n",
    "\n",
    "# 5. Modell-Vorhersage-Verteilung\n",
    "print(f\"\\n5Ô∏è‚É£ VORHERSAGE-VERTEILUNG:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Teste viele zuf√§llige Texte\n",
    "random_texts = [\n",
    "    \"good\", \"bad\", \"excellent\", \"terrible\", \"okay\", \n",
    "    \"amazing product\", \"poor quality\", \"works well\", \"broken\",\n",
    "    \"love it\", \"hate it\", \"perfect\", \"awful\", \"decent\"\n",
    "]\n",
    "\n",
    "predictions = []\n",
    "for text in random_texts:\n",
    "    X = vectorizer.transform([text])\n",
    "    pred_encoded = clf.predict(X)[0]\n",
    "    pred_original = label_encoder.inverse_transform([pred_encoded])[0]\n",
    "    predictions.append(pred_original)\n",
    "\n",
    "from collections import Counter\n",
    "pred_counts = Counter(predictions)\n",
    "print(\"Vorhersage-Verteilung f√ºr Test-Texte:\")\n",
    "for rating in sorted(pred_counts.keys()):\n",
    "    count = pred_counts[rating]\n",
    "    percentage = count / len(predictions) * 100\n",
    "    bar = \"‚ñà\" * int(percentage / 5)\n",
    "    print(f\"  {rating}‚≠ê: {count:2d}/{len(predictions)} ({percentage:4.1f}%) {bar}\")\n",
    "\n",
    "# 6. Probability-Analyse\n",
    "print(f\"\\n6Ô∏è‚É£ WAHRSCHEINLICHKEITS-ANALYSE:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "if hasattr(clf, 'predict_proba'):\n",
    "    # Teste extreme F√§lle\n",
    "    extreme_tests = {\n",
    "        \"amazing excellent perfect outstanding\": \"5‚≠ê erwartet\",\n",
    "        \"terrible horrible awful waste broken\": \"1‚≠ê erwartet\"\n",
    "    }\n",
    "    \n",
    "    for text, expected in extreme_tests.items():\n",
    "        X = vectorizer.transform([text])\n",
    "        probabilities = clf.predict_proba(X)[0]\n",
    "        pred_encoded = clf.predict(X)[0]\n",
    "        pred_original = label_encoder.inverse_transform([pred_encoded])[0]\n",
    "        \n",
    "        print(f\"\\nText: '{text}' ({expected})\")\n",
    "        print(f\"Vorhersage: {pred_original}‚≠ê\")\n",
    "        print(\"Wahrscheinlichkeiten:\")\n",
    "        for i, prob in enumerate(probabilities):\n",
    "            original_rating = label_encoder.inverse_transform([i])[0]\n",
    "            print(f\"  {original_rating}‚≠ê: {prob:.3f}\")\n",
    "\n",
    "# 7. Modell-Parameter pr√ºfen\n",
    "print(f\"\\n7Ô∏è‚É£ MODELL-PARAMETER:\")\n",
    "print(\"-\" * 30)\n",
    "if hasattr(clf, 'get_params'):\n",
    "    params = clf.get_params()\n",
    "    important_params = ['C', 'gamma', 'kernel', 'class_weight', 'random_state']\n",
    "    for param in important_params:\n",
    "        if param in params:\n",
    "            print(f\"  {param}: {params[param]}\")\n",
    "\n",
    "# 8. Training-Metriken nochmal pr√ºfen\n",
    "print(f\"\\n8Ô∏è‚É£ TRAINING-METRIKEN:\")\n",
    "print(\"-\" * 30)\n",
    "for key, value in mdl_dict.items():\n",
    "    if key not in ['model', 'model_name']:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# 9. DIAGNOSE-SCHLUSSFOLGERUNGEN\n",
    "print(f\"\\n9Ô∏è‚É£ DIAGNOSE-SCHLUSSFOLGERUNGEN:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "issues = []\n",
    "\n",
    "# Check 1: Alle Vorhersagen in 2-3 Bereich?\n",
    "unique_preds = set(predictions)\n",
    "if len(unique_preds) <= 2 and all(p in [2, 3] for p in unique_preds):\n",
    "    issues.append(\"‚ùå Modell vorhersagt nur 2-3 Sterne (bias Problem)\")\n",
    "\n",
    "# Check 2: Sehr schlechte Accuracy auf einfachen F√§llen\n",
    "simple_accuracy = sum(1 for p in predictions if p in [1, 4, 5]) / len(predictions)\n",
    "if simple_accuracy < 0.2:\n",
    "    issues.append(\"‚ùå Kann extreme Bewertungen (1‚≠ê, 5‚≠ê) nicht erkennen\")\n",
    "\n",
    "# Check 3: Training-Accuracy vs. Test-Performance\n",
    "train_acc = mdl_dict.get('train_accuracy', 0)\n",
    "if train_acc > 0.8:\n",
    "    issues.append(\"‚ùå M√∂gliches Overfitting (gute Training-Acc aber schlechte Real-World Performance)\")\n",
    "\n",
    "# Check 4: Label-Encoding Problem?\n",
    "if not all(isinstance(c, int) and 1 <= c <= 5 for c in label_encoder.classes_):\n",
    "    issues.append(\"‚ùå Label-Encoder Problem - falsche Klassen\")\n",
    "\n",
    "print(\"\\nüö® GEFUNDENE PROBLEME:\")\n",
    "if issues:\n",
    "    for issue in issues:\n",
    "        print(f\"  {issue}\")\n",
    "else:\n",
    "    print(\"  ‚úÖ Keine offensichtlichen Probleme gefunden\")\n",
    "\n",
    "print(f\"\\nüí° L√ñSUNGSVORSCHL√ÑGE:\")\n",
    "print(\"  1. Modell komplett neu trainieren\")\n",
    "print(\"  2. Andere Algorithmen testen (Random Forest, XGBoost)\")\n",
    "print(\"  3. Hyperparameter-Tuning verbessern\")\n",
    "print(\"  4. Datenqualit√§t pr√ºfen (sind die Labels korrekt?)\")\n",
    "print(\"  5. Feature-Engineering √ºberdenken\")\n",
    "print(\"  6. Class Imbalance behandeln (SMOTE, Class Weights)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8a42ed00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìã ZUSAMMENFASSUNG\n",
      "================================================================================\n",
      "üéØ Modell: Optimized Stacking\n",
      "üîß Feature-Kombination: combined\n",
      "üìä Test Samples: 15\n",
      "üìä Accuracy: 20.0%\n",
      "üìä MAE: 1.00 Sterne\n",
      "‚úÖ Richtige Vorhersagen: 3\n",
      "‚ùå Falsche Vorhersagen: 12\n",
      "üéØ Durchschnittliche Confidence: 44.8%\n",
      "\n",
      "üìÇ Datenquelle: Train/Test Splits\n",
      "üîß Features: 5,010\n",
      "üè∑Ô∏è Labels: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)]\n",
      "üìä Numerical Features: ['word_count', 'char_count', 'sentence_count', 'avg_word_length', 'exclamation_count', 'question_count', 'capital_ratio', 'sentiment_compound', 'sentiment_pos', 'sentiment_neg']\n",
      "üéØ Training Macro F1-Score: 0.443\n",
      "üéØ Training Test Accuracy: 0.604\n",
      "\n",
      "üöÄ INFERENCE DEMO ABGESCHLOSSEN!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 13) ZUSAMMENFASSUNG\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"üìã ZUSAMMENFASSUNG\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"üéØ Modell: {model_name}\")\n",
    "print(f\"üîß Feature-Kombination: {mdl_dict.get('feature_combination', 'unknown')}\")\n",
    "print(f\"üìä Test Samples: {len(y_true)}\")\n",
    "print(f\"üìä Accuracy: {accuracy:.1%}\")\n",
    "print(f\"üìä MAE: {mae:.2f} Sterne\")\n",
    "print(f\"‚úÖ Richtige Vorhersagen: {correct_count}\")\n",
    "print(f\"‚ùå Falsche Vorhersagen: {len(y_true) - correct_count}\")\n",
    "\n",
    "if confidence is not None:\n",
    "    print(f\"üéØ Durchschnittliche Confidence: {confidence.mean():.1%}\")\n",
    "\n",
    "print(f\"\\nüìÇ Datenquelle: {'Train/Test Splits' if data_source == 'splits' else 'Preprocessed CSV'}\")\n",
    "print(f\"üîß Features: {X_sample.shape[1]:,}\")\n",
    "print(f\"üè∑Ô∏è Labels: {sorted(label_encoder.classes_)}\")\n",
    "if numerical_features:\n",
    "    print(f\"üìä Numerical Features: {numerical_features}\")\n",
    "\n",
    "# Training-Informationen - PRIM√ÑR F1 MACRO\n",
    "macro_f1 = mdl_dict.get('macro_f1', 'N/A')\n",
    "train_acc = mdl_dict.get('test_accuracy', 'N/A')\n",
    "best_params = mdl_dict.get('best_params', {})\n",
    "\n",
    "if macro_f1 != 'N/A':\n",
    "    print(f\"üéØ Training Macro F1-Score: {macro_f1:.3f}\")\n",
    "if train_acc != 'N/A':\n",
    "    print(f\"üéØ Training Test Accuracy: {train_acc:.3f}\")\n",
    "if best_params:\n",
    "    print(f\"‚öôÔ∏è Best Params: {best_params}\")\n",
    "\n",
    "print(f\"\\nüöÄ INFERENCE DEMO ABGESCHLOSSEN!\")\n",
    "\n",
    "# Optional: Ergebnisse speichern\n",
    "# results_df = pd.DataFrame({\n",
    "#     'true_rating': y_true,\n",
    "#     'predicted_rating': y_pred_orig,\n",
    "#     'correct': y_true == y_pred_orig,\n",
    "#     'confidence': confidence if confidence is not None else [None] * len(y_true)\n",
    "# })\n",
    "# results_df.to_csv(\"inference_results.csv\", index=False)\n",
    "# print(f\"\\nüíæ Ergebnisse gespeichert als 'inference_results.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
