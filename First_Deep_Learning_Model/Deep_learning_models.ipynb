{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8a36f932-c1cf-4c0f-bd2c-046911e264c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Deep Learning Models for Customer Satisfaction Prediction\n",
    "Implements and compares 5 different deep learning architectures\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, LSTM, Bidirectional, Conv1D, MaxPooling1D, GlobalMaxPooling1D,\n",
    "    Embedding, Dropout, Input, concatenate, Attention, MultiHeadAttention,\n",
    "    LayerNormalization, Add, GlobalAveragePooling1D\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pickle\n",
    "import warnings\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2f6453c4-5664-4f7a-8c0f-6699aa0e9dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed data...\n",
      "Vocab size: 27319\n",
      "Max sequence length: 100\n",
      "Number of features: 14\n",
      "Number of classes: 5\n",
      "Training with balanced data: 19868 samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load preprocessed data\n",
    "print(\"Loading preprocessed data...\")\n",
    "data = np.load('data/preprocessed_data.npz')\n",
    "\n",
    "X_num_train = data['X_num_train']\n",
    "X_num_val = data['X_num_val']\n",
    "X_num_test = data['X_num_test']\n",
    "X_text_train = data['X_text_train']\n",
    "X_text_val = data['X_text_val']\n",
    "X_text_test = data['X_text_test']\n",
    "X_num_train_balanced = data['X_num_train_balanced']\n",
    "X_text_train_balanced = data['X_text_train_balanced']\n",
    "y_train = data['y_train']\n",
    "y_val = data['y_val']\n",
    "y_test = data['y_test']\n",
    "y_train_balanced = data['y_train_balanced']\n",
    "\n",
    "# Load metadata\n",
    "with open('data/metadata.pkl', 'rb') as f:\n",
    "    metadata = pickle.load(f)\n",
    "\n",
    "vocab_size = metadata['vocab_size']\n",
    "max_len = metadata['max_sequence_length']\n",
    "num_features = len(metadata['feature_columns'])\n",
    "num_classes = metadata['num_classes']\n",
    "class_weights = metadata['class_weights']\n",
    "class_names = metadata['class_names']\n",
    "\n",
    "print(f\"Vocab size: {vocab_size}\")\n",
    "print(f\"Max sequence length: {max_len}\")\n",
    "print(f\"Number of features: {num_features}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Training with balanced data: {X_text_train_balanced.shape[0]} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0828cd3b-034a-489e-9109-064f75d8fe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Input, Embedding, Conv1D, MaxPooling1D, LSTM, Dense, \n",
    "    Dropout, concatenate, BatchNormalization\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "class DeepLearningModels:\n",
    "    def __init__(self, vocab_size, max_len, num_features, num_classes, embedding_dim=100):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_len = max_len\n",
    "        self.num_features = num_features\n",
    "        self.num_classes = num_classes\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.models = {}\n",
    "        self.histories = {}\n",
    "        \n",
    "    def create_lstm_model(self):\n",
    "        \"\"\"Model 1: LSTM-based RNN for sequential text processing\"\"\"\n",
    "        # Text input branch\n",
    "        text_input = Input(shape=(self.max_len,), name='text_input')\n",
    "        text_embedding = Embedding(self.vocab_size, self.embedding_dim, mask_zero=True)(text_input)\n",
    "        text_lstm = LSTM(64, dropout=0.3, recurrent_dropout=0.3)(text_embedding)\n",
    "        \n",
    "        # Numerical input branch\n",
    "        num_input = Input(shape=(self.num_features,), name='numerical_input')\n",
    "        num_dense = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(num_input)\n",
    "        num_dropout = Dropout(0.3)(num_dense)\n",
    "        \n",
    "        # Combine branches\n",
    "        combined = concatenate([text_lstm, num_dropout])\n",
    "        hidden = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(combined)\n",
    "        hidden = Dropout(0.4)(hidden)\n",
    "        hidden = Dense(32, activation='relu')(hidden)\n",
    "        output = Dense(self.num_classes, activation='softmax')(hidden)\n",
    "        \n",
    "        model = Model(inputs=[text_input, num_input], outputs=output)\n",
    "        return model\n",
    "    \n",
    "    def create_bilstm_attention_model(self):\n",
    "        \"\"\"Model 2: Bidirectional LSTM with attention mechanism\"\"\"\n",
    "        # Text input branch\n",
    "        text_input = Input(shape=(self.max_len,), name='text_input')\n",
    "        text_embedding = Embedding(self.vocab_size, self.embedding_dim, mask_zero=True)(text_input)\n",
    "        \n",
    "        # Bidirectional LSTM\n",
    "        bilstm = Bidirectional(LSTM(64, dropout=0.3, recurrent_dropout=0.3, return_sequences=True))(text_embedding)\n",
    "        \n",
    "        # Self-attention mechanism\n",
    "        attention = MultiHeadAttention(num_heads=4, key_dim=64)(bilstm, bilstm)\n",
    "        attention = Add()([bilstm, attention])\n",
    "        attention = LayerNormalization()(attention)\n",
    "        \n",
    "        # Global pooling\n",
    "        text_features = GlobalAveragePooling1D()(attention)\n",
    "        \n",
    "        # Numerical input branch\n",
    "        num_input = Input(shape=(self.num_features,), name='numerical_input')\n",
    "        num_dense = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(num_input)\n",
    "        num_dropout = Dropout(0.3)(num_dense)\n",
    "        \n",
    "        # Combine branches\n",
    "        combined = concatenate([text_features, num_dropout])\n",
    "        hidden = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(combined)\n",
    "        hidden = Dropout(0.4)(hidden)\n",
    "        hidden = Dense(64, activation='relu')(hidden)\n",
    "        hidden = Dropout(0.3)(hidden)\n",
    "        output = Dense(self.num_classes, activation='softmax')(hidden)\n",
    "        \n",
    "        model = Model(inputs=[text_input, num_input], outputs=output)\n",
    "        return model\n",
    "\n",
    "    def create_fast_bilstm_attention_model(self):\n",
    "        \"\"\"Optimized BiLSTM with Attention Model for Speed\"\"\"\n",
    "        # Text input branch\n",
    "        text_input = Input(shape=(self.max_len,), name='text_input')\n",
    "        \n",
    "        # Optimized embedding with smaller dimension\n",
    "        text_embedding = Embedding(\n",
    "            self.vocab_size, \n",
    "            min(128, self.embedding_dim),  # Reduced embedding size\n",
    "            mask_zero=True\n",
    "        )(text_input)\n",
    "        \n",
    "        # Faster Bidirectional LSTM\n",
    "        bilstm = Bidirectional(\n",
    "            LSTM(64,  # Maintained size but optimized settings\n",
    "                dropout=0.2,  # Reduced dropout\n",
    "                recurrent_dropout=0.1,  # Reduced recurrent dropout\n",
    "                return_sequences=True,\n",
    "                activation='tanh',  # Faster than default\n",
    "                recurrent_activation='sigmoid')  # Faster than default\n",
    "        )(text_embedding)\n",
    "        \n",
    "        # Optimized attention mechanism\n",
    "        attention = MultiHeadAttention(\n",
    "            num_heads=2,  # Reduced heads\n",
    "            key_dim=64,  # Matches LSTM units\n",
    "            dropout=0.1  # Added attention dropout\n",
    "        )(bilstm, bilstm)\n",
    "        \n",
    "        # Simplified residual connection\n",
    "        attention = Add()([bilstm, attention])\n",
    "        \n",
    "        # Removed LayerNorm for speed (optional: can keep if critical for performance)\n",
    "        \n",
    "        # Efficient context extraction\n",
    "        text_features = GlobalAveragePooling1D()(attention)\n",
    "        \n",
    "        # Numerical input branch (optimized)\n",
    "        num_input = Input(shape=(self.num_features,), name='numerical_input')\n",
    "        num_dense = Dense(32, activation='relu')(num_input)  # Removed regularizer\n",
    "        \n",
    "        # Combine branches\n",
    "        combined = concatenate([text_features, num_dense])\n",
    "        \n",
    "        # Optimized classifier head\n",
    "        hidden = Dense(64, activation='relu')(combined)  # Smaller layer\n",
    "        hidden = Dropout(0.3)(hidden)\n",
    "        output = Dense(self.num_classes, activation='softmax')(hidden)\n",
    "        \n",
    "        model = Model(inputs=[text_input, num_input], outputs=output)\n",
    "        return model\n",
    "        \n",
    "    def create_robust_model(self):\n",
    "        # Text\n",
    "        text_input = Input(shape=(self.max_len,))\n",
    "        x = Embedding(self.vocab_size, 128)(text_input)\n",
    "        x = Bidirectional(LSTM(64))(x)\n",
    "        \n",
    "        # Numerical\n",
    "        num_input = Input(shape=(self.num_features,))\n",
    "        y = Dense(64)(num_input)\n",
    "        \n",
    "        # Combined\n",
    "        z = concatenate([x, y])\n",
    "        z = Dense(128, activation='relu')(z)\n",
    "        output = Dense(self.num_classes, activation='softmax')(z)\n",
    "        \n",
    "        model = Model(inputs=[text_input, num_input], outputs=output)\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    \n",
    "    from keras.layers import Attention  # Use Keras' built-in attention\n",
    "\n",
    "    def create_accurate_bilstm_attention_model(self):\n",
    "        \"\"\"High-performance BiLSTM with Attention\"\"\"\n",
    "        # Text input branch\n",
    "        text_input = Input(shape=(self.max_len,), name='text_input')\n",
    "        text_embedding = Embedding(\n",
    "            self.vocab_size,\n",
    "            self.embedding_dim * 2,  # Increased capacity\n",
    "            mask_zero=True\n",
    "        )(text_input)\n",
    "        \n",
    "        # Enhanced Bidirectional LSTM\n",
    "        bilstm = Bidirectional(\n",
    "            LSTM(128,  # Doubled units\n",
    "                dropout=0.3,\n",
    "                recurrent_dropout=0.25,\n",
    "                return_sequences=True,\n",
    "                kernel_regularizer=l2(1e-4))  # Added regularization\n",
    "        )(text_embedding)\n",
    "        bilstm = BatchNormalization()(bilstm)  # Stabilizes training\n",
    "        \n",
    "        # Powerful attention mechanism\n",
    "        attention = MultiHeadAttention(\n",
    "            num_heads=8,  # More attention heads\n",
    "            key_dim=128,  # Matches LSTM units\n",
    "            dropout=0.2,\n",
    "            kernel_regularizer=l2(1e-4)\n",
    "        )(bilstm, bilstm)\n",
    "        \n",
    "        # Residual connection with layer norm\n",
    "        attention = Add()([bilstm, attention])\n",
    "        attention = LayerNormalization()(attention)\n",
    "        \n",
    "        # Context extraction\n",
    "        text_features = GlobalAveragePooling1D()(attention)\n",
    "        \n",
    "        # Enhanced numerical branch\n",
    "        num_input = Input(shape=(self.num_features,), name='numerical_input')\n",
    "        num_dense = Dense(64, activation='relu', kernel_regularizer=l2(1e-4))(num_input)\n",
    "        num_dense = BatchNormalization()(num_dense)\n",
    "        \n",
    "        # Feature fusion\n",
    "        combined = concatenate([text_features, num_dense])\n",
    "        combined = Dropout(0.4)(combined)\n",
    "        \n",
    "        # Deep classifier head\n",
    "        hidden = Dense(256, activation='relu', kernel_regularizer=l2(1e-4))(combined)\n",
    "        hidden = BatchNormalization()(hidden)\n",
    "        hidden = Dropout(0.4)(hidden)\n",
    "        hidden = Dense(128, activation='relu')(hidden)\n",
    "        output = Dense(self.num_classes, activation='softmax')(hidden)\n",
    "        \n",
    "        model = Model(inputs=[text_input, num_input], outputs=output)\n",
    "        return model\n",
    "          \n",
    "    def create_cnn_model(self):\n",
    "        \"\"\"Model 3: CNN for text classification with multiple filter sizes\"\"\"\n",
    "        # Text input branch\n",
    "        text_input = Input(shape=(self.max_len,), name='text_input')\n",
    "        text_embedding = Embedding(self.vocab_size, self.embedding_dim)(text_input)\n",
    "        \n",
    "        # Multiple CNN branches with different filter sizes\n",
    "        conv_branches = []\n",
    "        filter_sizes = [3, 4, 5]\n",
    "        \n",
    "        for filter_size in filter_sizes:\n",
    "            conv = Conv1D(64, filter_size, activation='relu', padding='same')(text_embedding)\n",
    "            conv = Dropout(0.3)(conv)\n",
    "            conv = MaxPooling1D(2)(conv)\n",
    "            conv = Conv1D(32, filter_size, activation='relu', padding='same')(conv)\n",
    "            conv = GlobalMaxPooling1D()(conv)\n",
    "            conv_branches.append(conv)\n",
    "        \n",
    "        # Combine CNN branches\n",
    "        if len(conv_branches) > 1:\n",
    "            text_features = concatenate(conv_branches)\n",
    "        else:\n",
    "            text_features = conv_branches[0]\n",
    "        \n",
    "        # Numerical input branch\n",
    "        num_input = Input(shape=(self.num_features,), name='numerical_input')\n",
    "        num_dense = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(num_input)\n",
    "        num_dropout = Dropout(0.3)(num_dense)\n",
    "        \n",
    "        # Combine branches\n",
    "        combined = concatenate([text_features, num_dropout])\n",
    "        hidden = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(combined)\n",
    "        hidden = Dropout(0.4)(hidden)\n",
    "        hidden = Dense(64, activation='relu')(hidden)\n",
    "        output = Dense(self.num_classes, activation='softmax')(hidden)\n",
    "        \n",
    "        model = Model(inputs=[text_input, num_input], outputs=output)\n",
    "        return model\n",
    "    \n",
    "    def create_transformer_model(self):\n",
    "        \"\"\"Model 4: Transformer-based model (simplified BERT-like architecture)\"\"\"\n",
    "        # Text input branch\n",
    "        text_input = Input(shape=(self.max_len,), name='text_input')\n",
    "        text_embedding = Embedding(self.vocab_size, self.embedding_dim)(text_input)\n",
    "        \n",
    "        # Positional encoding (simplified)\n",
    "        positions = tf.range(start=0, limit=self.max_len, delta=1)\n",
    "        position_embedding = Embedding(self.max_len, self.embedding_dim)(positions)\n",
    "        text_embedded = text_embedding + position_embedding\n",
    "        \n",
    "        # Transformer blocks\n",
    "        for _ in range(2):  # 2 transformer blocks\n",
    "            # Multi-head attention\n",
    "            attention = MultiHeadAttention(num_heads=8, key_dim=self.embedding_dim//8)(\n",
    "                text_embedded, text_embedded\n",
    "            )\n",
    "            attention = Dropout(0.1)(attention)\n",
    "            attention = Add()([text_embedded, attention])\n",
    "            attention = LayerNormalization()(attention)\n",
    "            \n",
    "            # Feed forward\n",
    "            ff = Dense(256, activation='relu')(attention)\n",
    "            ff = Dropout(0.1)(ff)\n",
    "            ff = Dense(self.embedding_dim)(ff)\n",
    "            ff = Add()([attention, ff])\n",
    "            text_embedded = LayerNormalization()(ff)\n",
    "        \n",
    "        # Global pooling\n",
    "        text_features = GlobalAveragePooling1D()(text_embedded)\n",
    "        \n",
    "        # Numerical input branch\n",
    "        num_input = Input(shape=(self.num_features,), name='numerical_input')\n",
    "        num_dense = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(num_input)\n",
    "        num_dropout = Dropout(0.3)(num_dense)\n",
    "        \n",
    "        # Combine branches\n",
    "        combined = concatenate([text_features, num_dropout])\n",
    "        hidden = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(combined)\n",
    "        hidden = Dropout(0.4)(hidden)\n",
    "        hidden = Dense(64, activation='relu')(hidden)\n",
    "        output = Dense(self.num_classes, activation='softmax')(hidden)\n",
    "        \n",
    "        model = Model(inputs=[text_input, num_input], outputs=output)\n",
    "        return model\n",
    "    \n",
    "    def create_hybrid_cnn_lstm_model(self):\n",
    "        \"\"\"Model 5: Hybrid CNN-LSTM model\"\"\"\n",
    "        # Text input branch\n",
    "        text_input = Input(shape=(self.max_len,), name='text_input')\n",
    "        text_embedding = Embedding(self.vocab_size, self.embedding_dim)(text_input)\n",
    "        \n",
    "        # CNN feature extraction\n",
    "        conv1 = Conv1D(64, 3, activation='relu', padding='same')(text_embedding)\n",
    "        conv1 = Dropout(0.3)(conv1)\n",
    "        conv2 = Conv1D(64, 5, activation='relu', padding='same')(text_embedding)\n",
    "        conv2 = Dropout(0.3)(conv2)\n",
    "        \n",
    "        # Combine CNN features\n",
    "        conv_combined = concatenate([conv1, conv2])\n",
    "        \n",
    "        # LSTM on top of CNN features\n",
    "        lstm_out = LSTM(64, dropout=0.3, recurrent_dropout=0.3)(conv_combined)\n",
    "        \n",
    "        # Numerical input branch\n",
    "        num_input = Input(shape=(self.num_features,), name='numerical_input')\n",
    "        num_dense = Dense(32, activation='relu', kernel_regularizer=l2(0.01))(num_input)\n",
    "        num_dropout = Dropout(0.3)(num_dense)\n",
    "        \n",
    "        # Combine branches\n",
    "        combined = concatenate([lstm_out, num_dropout])\n",
    "        hidden = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(combined)\n",
    "        hidden = Dropout(0.4)(hidden)\n",
    "        hidden = Dense(64, activation='relu')(hidden)\n",
    "        output = Dense(self.num_classes, activation='softmax')(hidden)\n",
    "        \n",
    "        model = Model(inputs=[text_input, num_input], outputs=output)\n",
    "        return model\n",
    "    \n",
    "    def create_hybrid_cnn_lstm_model_modified(self):\n",
    "        \"\"\"Fixed version with all required imports\"\"\"\n",
    "        # Text input branch\n",
    "        text_input = Input(shape=(self.max_len,), name='text_input')\n",
    "        text_embedding = Embedding(self.vocab_size, self.embedding_dim)(text_input)\n",
    "        \n",
    "        # CNN with MaxPooling\n",
    "        conv1 = Conv1D(128, 3, activation='relu', padding='same')(text_embedding)\n",
    "        conv1 = MaxPooling1D(2)(conv1)\n",
    "        conv2 = Conv1D(128, 5, activation='relu', padding='same')(text_embedding)\n",
    "        conv2 = MaxPooling1D(2)(conv2)\n",
    "        \n",
    "        conv_combined = concatenate([conv1, conv2])\n",
    "        conv_combined = BatchNormalization()(conv_combined)  # Now properly imported\n",
    "        \n",
    "        # LSTM\n",
    "        lstm_out = LSTM(128, dropout=0.2, recurrent_dropout=0.2)(conv_combined)\n",
    "        \n",
    "        # Numerical branch\n",
    "        num_input = Input(shape=(self.num_features,), name='numerical_input')\n",
    "        num_dense = Dense(32, activation='relu')(num_input)\n",
    "        \n",
    "        # Combine branches\n",
    "        combined = concatenate([lstm_out, num_dense])\n",
    "        hidden = Dense(128, activation='relu')(combined)\n",
    "        output = Dense(self.num_classes, activation='softmax')(hidden)\n",
    "        \n",
    "        model = Model(inputs=[text_input, num_input], outputs=output)\n",
    "        return model\n",
    "    \n",
    "    def compile_model(self, model, learning_rate=0.001):\n",
    "        \"\"\"Compile model with appropriate optimizer and loss function\"\"\"\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=learning_rate),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n",
    "    \n",
    "    def create_callbacks(self):\n",
    "        \"\"\"Create training callbacks\"\"\"\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        reduce_lr = ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-7\n",
    "        )\n",
    "        \n",
    "        return [early_stopping, reduce_lr]\n",
    "    \n",
    "    def train_model(self, model, model_name, X_text_train, X_num_train, y_train,\n",
    "                   X_text_val, X_num_val, y_val, class_weights, epochs=100):\n",
    "        \"\"\"Train a model with given data\"\"\"\n",
    "        print(f\"\\nTraining {model_name}...\")\n",
    "        \n",
    "        callbacks = self.create_callbacks()\n",
    "        \n",
    "        history = model.fit(\n",
    "            [X_text_train, X_num_train], y_train,\n",
    "            validation_data=([X_text_val, X_num_val], y_val),\n",
    "            epochs=epochs,\n",
    "            batch_size=16,\n",
    "            class_weight=class_weights,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        self.models[model_name] = model\n",
    "        self.histories[model_name] = history\n",
    "        \n",
    "        return model, history\n",
    "    \n",
    "    def evaluate_model(self, model, model_name, X_text_test, X_num_test, y_test, class_names):\n",
    "        \"\"\"Evaluate model performance\"\"\"\n",
    "        print(f\"\\nEvaluating {model_name}...\")\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_proba = model.predict([X_text_test, X_num_test])\n",
    "        y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
    "        f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "        \n",
    "        # Multi-class ROC AUC\n",
    "        try:\n",
    "            auc_score = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='weighted')\n",
    "        except:\n",
    "            auc_score = 0.0\n",
    "        \n",
    "        # Precision, Recall, F1 per class\n",
    "        precision, recall, f1, support = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "        \n",
    "        # Classification report\n",
    "        report = classification_report(y_test, y_pred, target_names=class_names, output_dict=True)\n",
    "        \n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        results = {\n",
    "            'model_name': model_name,\n",
    "            'accuracy': accuracy,\n",
    "            'f1_weighted': f1_weighted,\n",
    "            'f1_macro': f1_macro,\n",
    "            'auc_score': auc_score,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_per_class': f1,\n",
    "            'support': support,\n",
    "            'classification_report': report,\n",
    "            'confusion_matrix': cm,\n",
    "            'y_pred': y_pred,\n",
    "            'y_pred_proba': y_pred_proba\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def plot_training_history(self, model_name):\n",
    "        \"\"\"Plot training history\"\"\"\n",
    "        if model_name not in self.histories:\n",
    "            return\n",
    "        \n",
    "        history = self.histories[model_name]\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        \n",
    "        # Plot accuracy\n",
    "        ax1.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "        ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "        ax1.set_title(f'{model_name} - Accuracy')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Accuracy')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True)\n",
    "        \n",
    "        # Plot loss\n",
    "        ax2.plot(history.history['loss'], label='Training Loss')\n",
    "        ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        ax2.set_title(f'{model_name} - Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'charts/{model_name.lower().replace(\" \", \"_\")}_training_history.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_confusion_matrix(self, results, class_names):\n",
    "        \"\"\"Plot confusion matrix\"\"\"\n",
    "        cm = results['confusion_matrix']\n",
    "        model_name = results['model_name']\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.title(f'{model_name} - Confusion Matrix')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'charts/{model_name.lower().replace(\" \", \"_\")}_confusion_matrix.png', \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    def save_all_models(self, all_results):\n",
    "        \"\"\"Save all trained models with their evaluation results and supporting files for API use\"\"\"\n",
    "        # Create directories if they don't exist\n",
    "        os.makedirs('api_models', exist_ok=True)\n",
    "        os.makedirs('api_models/data', exist_ok=True)\n",
    "\n",
    "        # Actual features from your Temu reviews dataset\n",
    "        feature_columns = [\n",
    "            'ReviewCount', 'UserCountry_encoded',\n",
    "            'text_length', 'word_count', 'avg_word_length',\n",
    "            'exclamation_count', 'question_count', 'upper_case_ratio',\n",
    "            'title_text_length', 'title_word_count', 'title_avg_word_length',\n",
    "            'title_exclamation_count', 'title_question_count', 'title_upper_case_ratio'\n",
    "        ]\n",
    "\n",
    "        # Class names based on ReviewRating (1-5 stars)\n",
    "        class_names = [\n",
    "            '1 Star - Very Poor',\n",
    "            '2 Stars - Poor',\n",
    "            '3 Stars - Average',\n",
    "            '4 Stars - Good',\n",
    "            '5 Stars - Excellent'\n",
    "        ]\n",
    "\n",
    "        # Create a package for each model that contains everything needed for serving\n",
    "        for result in all_results:\n",
    "            model_name = result['model_name']\n",
    "            if model_name in self.models:\n",
    "                # Create a directory for this model\n",
    "                model_dir = os.path.join('api_models', model_name.lower().replace(' ', '_'))\n",
    "                os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "                # 1. Save the model in SavedModel format\n",
    "                model_path = os.path.join(model_dir, 'model.keras')\n",
    "                self.models[model_name].save(model_path)\n",
    "\n",
    "                # 2. Save metadata needed for preprocessing\n",
    "                metadata = {\n",
    "                    'max_sequence_length': self.max_len,\n",
    "                    'feature_columns': feature_columns,\n",
    "                    'class_names': class_names,\n",
    "                    'input_details': {\n",
    "                        'text_input': {\n",
    "                            'shape': [None, self.max_len],\n",
    "                            'dtype': 'int32',\n",
    "                            'description': 'Tokenized review text from ReviewText column'\n",
    "                        },\n",
    "                        'numerical_input': {\n",
    "                            'shape': [None, len(feature_columns)],\n",
    "                            'dtype': 'float32',\n",
    "                            'description': f'Numerical features in order: {\", \".join(feature_columns)}'\n",
    "                        }\n",
    "                    },\n",
    "                    'output_details': {\n",
    "                        'description': 'Probability scores for each rating level (1-5 stars)',\n",
    "                        'class_order': class_names\n",
    "                    },\n",
    "                    'data_source': 'temu_reviews_cleaned.csv',\n",
    "                    'text_columns_used': ['ReviewText', 'ReviewTitle'],  # Which text columns were used\n",
    "                    'model_format': 'keras'  # Indicate the saved format\n",
    "                }\n",
    "\n",
    "                with open(os.path.join(model_dir, 'metadata.json'), 'w') as f:\n",
    "                    json.dump(metadata, f, indent=2)\n",
    "\n",
    "                print(f\"✅ Saved API-ready {model_name} package to {model_dir}\")\n",
    "\n",
    "                # Update the result with the path\n",
    "                result['api_model_path'] = model_dir\n",
    "            else:\n",
    "                print(f\"⚠️ Model {model_name} not found in trained models\")\n",
    "\n",
    "        # Save tokenizer if exists\n",
    "        if hasattr(self, 'tokenizer'):\n",
    "            tokenizer_path = os.path.join('api_models', 'tokenizer.pkl')\n",
    "            with open(tokenizer_path, 'wb') as f:\n",
    "                pickle.dump(self.tokenizer, f)\n",
    "            print(f\"✅ Saved tokenizer to {tokenizer_path}\")\n",
    "\n",
    "        # Save complete results\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        results_path = os.path.join('api_models', 'data', f'model_results_{timestamp}.pkl')\n",
    "        with open(results_path, 'wb') as f:\n",
    "            pickle.dump(all_results, f)\n",
    "\n",
    "        print(f\"\\nAll models saved in API-ready format.\")\n",
    "        print(f\"You can now deploy any model by copying its directory to your API server.\")\n",
    "        return results_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ba4430a1-a52c-495c-8b63-d23d3b97a906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Building and training LSTM Model\n",
      "==================================================\n",
      "\n",
      "LSTM Model Architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_19\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_19\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ text_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ numerical_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,731,900</span> │ text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_79 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> │ numerical_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">42,240</span> │ embedding_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│                               │                           │                 │ not_equal_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_79[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],             │\n",
       "│                               │                           │                 │ dropout_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ concatenate_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_80[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span> │ dense_81[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ text_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ numerical_input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_26 (\u001b[38;5;33mEmbedding\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)          │       \u001b[38;5;34m2,731,900\u001b[0m │ text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal_14 (\u001b[38;5;33mNotEqual\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_79 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │             \u001b[38;5;34m480\u001b[0m │ numerical_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_18 (\u001b[38;5;33mLSTM\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │          \u001b[38;5;34m42,240\u001b[0m │ embedding_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│                               │                           │                 │ not_equal_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_54 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_79[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_26 (\u001b[38;5;33mConcatenate\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ lstm_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],             │\n",
       "│                               │                           │                 │ dropout_54[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_80 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m6,208\u001b[0m │ concatenate_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_55 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_80[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_81 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │           \u001b[38;5;34m2,080\u001b[0m │ dropout_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_82 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                 │             \u001b[38;5;34m165\u001b[0m │ dense_81[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,783,073</span> (10.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,783,073\u001b[0m (10.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,783,073</span> (10.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,783,073\u001b[0m (10.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LSTM Model...\n",
      "Epoch 1/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 117ms/step - accuracy: 0.2561 - loss: 2.6519 - val_accuracy: 0.1875 - val_loss: 2.4667 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 113ms/step - accuracy: 0.3404 - loss: 2.0127 - val_accuracy: 0.2324 - val_loss: 2.0706 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 113ms/step - accuracy: 0.4347 - loss: 1.8319 - val_accuracy: 0.4096 - val_loss: 1.8242 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 123ms/step - accuracy: 0.4944 - loss: 1.7354 - val_accuracy: 0.4515 - val_loss: 1.7426 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 113ms/step - accuracy: 0.5408 - loss: 1.6491 - val_accuracy: 0.4574 - val_loss: 1.8233 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 112ms/step - accuracy: 0.5707 - loss: 1.5813 - val_accuracy: 0.4956 - val_loss: 1.6940 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 120ms/step - accuracy: 0.5944 - loss: 1.4956 - val_accuracy: 0.5029 - val_loss: 1.6930 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 129ms/step - accuracy: 0.6229 - loss: 1.4075 - val_accuracy: 0.5294 - val_loss: 1.6275 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 125ms/step - accuracy: 0.6489 - loss: 1.3172 - val_accuracy: 0.4993 - val_loss: 1.8232 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 119ms/step - accuracy: 0.6720 - loss: 1.2279 - val_accuracy: 0.5426 - val_loss: 1.7280 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 113ms/step - accuracy: 0.6845 - loss: 1.1588 - val_accuracy: 0.5551 - val_loss: 1.7209 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 115ms/step - accuracy: 0.7072 - loss: 1.0822 - val_accuracy: 0.5610 - val_loss: 1.7961 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 114ms/step - accuracy: 0.7235 - loss: 1.0175 - val_accuracy: 0.5346 - val_loss: 1.8709 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 114ms/step - accuracy: 0.7410 - loss: 0.9292 - val_accuracy: 0.5507 - val_loss: 1.9231 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 116ms/step - accuracy: 0.7665 - loss: 0.8322 - val_accuracy: 0.5574 - val_loss: 1.8797 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 115ms/step - accuracy: 0.7658 - loss: 0.8094 - val_accuracy: 0.5544 - val_loss: 1.9978 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 106ms/step - accuracy: 0.7795 - loss: 0.7619 - val_accuracy: 0.5485 - val_loss: 2.0666 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 103ms/step - accuracy: 0.7904 - loss: 0.7221 - val_accuracy: 0.5640 - val_loss: 1.9456 - learning_rate: 5.0000e-04\n",
      "\n",
      "Evaluating LSTM Model...\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step\n",
      "\n",
      "LSTM Model Results:\n",
      "Accuracy: 0.5278\n",
      "F1-Score (Weighted): 0.5830\n",
      "F1-Score (Macro): 0.3486\n",
      "AUC Score: 0.8413\n"
     ]
    }
   ],
   "source": [
    "# model_configs = [\n",
    "#    ('LSTM Model', model_builder.create_lstm_model),\n",
    "#    ('BiLSTM with Attention', model_builder.create_bilstm_attention_model),\n",
    "#    ('CNN Model', model_builder.create_cnn_model),\n",
    "#    ('Transformer Model', model_builder.create_transformer_model),\n",
    "#    ('Hybrid CNN-LSTM', model_builder.create_hybrid_cnn_lstm_model)\n",
    "# ]\n",
    "\n",
    "\n",
    "# Initialize model builder\n",
    "model_builder = DeepLearningModels(vocab_size, max_len, num_features, num_classes)\n",
    "\n",
    "#'LSTM Model', model_builder.create_lstm_model)\n",
    "# Define models to train\n",
    "model_configs = [\n",
    "    ('LSTM Model', model_builder.create_lstm_model)\n",
    "]\n",
    "\n",
    "# Train and evaluate all models\n",
    "all_results = []\n",
    "\n",
    "for model_name, model_func in model_configs:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Building and training {model_name}\")\n",
    "    print('='*50)\n",
    "    \n",
    "    # Create and compile model\n",
    "    model = model_func()\n",
    "    model = model_builder.compile_model(model)\n",
    "    \n",
    "    print(f\"\\n{model_name} Architecture:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Train model\n",
    "    model, history = model_builder.train_model(\n",
    "        model, model_name,\n",
    "        X_text_train_balanced, X_num_train_balanced, y_train_balanced,\n",
    "        X_text_val, X_num_val, y_val,\n",
    "        class_weights, epochs=50\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    model_builder.plot_training_history(model_name)\n",
    "    \n",
    "    # Evaluate model\n",
    "    results = model_builder.evaluate_model(\n",
    "        model, model_name, X_text_test, X_num_test, y_test, class_names\n",
    "    )\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    model_builder.plot_confusion_matrix(results, class_names)\n",
    "    \n",
    "    all_results.append(results)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"F1-Score (Weighted): {results['f1_weighted']:.4f}\")\n",
    "    print(f\"F1-Score (Macro): {results['f1_macro']:.4f}\")\n",
    "    print(f\"AUC Score: {results['auc_score']:.4f}\")\n",
    "    \n",
    "    # Save results\n",
    "    with open('data/model_results.pkl', 'wb') as f:\n",
    "        pickle.dump(all_results, f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a92129e1-1a20-434f-86bd-829a1421105d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Building and training BiLSTM with Attention\n",
      "==================================================\n",
      "\n",
      "BiLSTM with Attention Architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_20\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_20\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,496,832</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional_13              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │ embedding_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)               │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                               │                           │                 │ dense_83[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ concatenate_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │ dense_84[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_27 (\u001b[38;5;33mEmbedding\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │       \u001b[38;5;34m3,496,832\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional_13              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m98,816\u001b[0m │ embedding_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)               │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_83 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m960\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_27 (\u001b[38;5;33mConcatenate\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ bidirectional_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                               │                           │                 │ dense_83[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_84 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m24,704\u001b[0m │ concatenate_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_85 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                 │             \u001b[38;5;34m645\u001b[0m │ dense_84[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,621,957</span> (13.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,621,957\u001b[0m (13.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,621,957</span> (13.82 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,621,957\u001b[0m (13.82 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training BiLSTM with Attention...\n",
      "Epoch 1/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 101ms/step - accuracy: 0.3215 - loss: 2.0184 - val_accuracy: 0.4419 - val_loss: 1.6866 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 103ms/step - accuracy: 0.5119 - loss: 1.6319 - val_accuracy: 0.4346 - val_loss: 1.9196 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 99ms/step - accuracy: 0.6029 - loss: 1.3997 - val_accuracy: 0.4449 - val_loss: 2.1414 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 98ms/step - accuracy: 0.6674 - loss: 1.1775 - val_accuracy: 0.4757 - val_loss: 2.0609 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 98ms/step - accuracy: 0.7148 - loss: 0.9478 - val_accuracy: 0.5066 - val_loss: 2.1444 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 99ms/step - accuracy: 0.7651 - loss: 0.7467 - val_accuracy: 0.5713 - val_loss: 1.8864 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 99ms/step - accuracy: 0.8152 - loss: 0.5572 - val_accuracy: 0.5963 - val_loss: 1.9514 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 99ms/step - accuracy: 0.8545 - loss: 0.3910 - val_accuracy: 0.6221 - val_loss: 2.1447 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 100ms/step - accuracy: 0.8864 - loss: 0.2901 - val_accuracy: 0.6324 - val_loss: 2.3221 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 100ms/step - accuracy: 0.9033 - loss: 0.2401 - val_accuracy: 0.5934 - val_loss: 2.7365 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 100ms/step - accuracy: 0.9159 - loss: 0.2033 - val_accuracy: 0.6294 - val_loss: 2.6736 - learning_rate: 5.0000e-04\n",
      "\n",
      "Evaluating BiLSTM with Attention...\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step\n",
      "\n",
      "BiLSTM with Attention Results:\n",
      "Accuracy: 0.4200\n",
      "F1-Score (Weighted): 0.4980\n",
      "F1-Score (Macro): 0.3047\n",
      "AUC Score: 0.8495\n"
     ]
    }
   ],
   "source": [
    "# model_configs = [\n",
    "#    ('LSTM Model', model_builder.create_lstm_model),\n",
    "#    ('BiLSTM with Attention', model_builder.create_bilstm_attention_model),\n",
    "#    ('CNN Model', model_builder.create_cnn_model),\n",
    "#    ('Transformer Model', model_builder.create_transformer_model),\n",
    "#    ('Hybrid CNN-LSTM', model_builder.create_hybrid_cnn_lstm_model)\n",
    "# ]\n",
    "\n",
    "\n",
    "# Initialize model builder\n",
    "model_builder = DeepLearningModels(vocab_size, max_len, num_features, num_classes)\n",
    "\n",
    "#'BiLSTM with Attention', model_builder.create_bilstm_attention_model)\n",
    "# Define models to train\n",
    "model_configs = [\n",
    "    ('BiLSTM with Attention', model_builder.create_robust_model)\n",
    "]\n",
    "\n",
    "# Train and evaluate all models\n",
    "for model_name, model_func in model_configs:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Building and training {model_name}\")\n",
    "    print('='*50)\n",
    "    \n",
    "    # Create and compile model\n",
    "    model = model_func()\n",
    "    model = model_builder.compile_model(model)\n",
    "    \n",
    "    print(f\"\\n{model_name} Architecture:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Train model\n",
    "    model, history = model_builder.train_model(\n",
    "        model, model_name,\n",
    "        X_text_train_balanced, X_num_train_balanced, y_train_balanced,\n",
    "        X_text_val, X_num_val, y_val,\n",
    "        class_weights, epochs=50\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    model_builder.plot_training_history(model_name)\n",
    "    \n",
    "    # Evaluate model\n",
    "    results = model_builder.evaluate_model(\n",
    "        model, model_name, X_text_test, X_num_test, y_test, class_names\n",
    "    )\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    model_builder.plot_confusion_matrix(results, class_names)\n",
    "    \n",
    "    all_results.append(results)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"F1-Score (Weighted): {results['f1_weighted']:.4f}\")\n",
    "    print(f\"F1-Score (Macro): {results['f1_macro']:.4f}\")\n",
    "    print(f\"AUC Score: {results['auc_score']:.4f}\")\n",
    "    \n",
    "    # Save results\n",
    "    with open('data/model_results.pkl', 'wb') as f:\n",
    "        pickle.dump(all_results, f)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e91acc43-c07e-429b-accc-4d9be54efa99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Building and training CNN Model\n",
      "==================================================\n",
      "\n",
      "CNN Model Architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_21\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_21\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ text_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,731,900</span> │ text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">19,264</span> │ embedding_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,664</span> │ embedding_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,064</span> │ embedding_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_14              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_56[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_15              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_16              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,176</span> │ max_pooling1d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span> │ max_pooling1d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,272</span> │ max_pooling1d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ numerical_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_max_pooling1d_6        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_max_pooling1d_7        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_max_pooling1d_8        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> │ numerical_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooling1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ global_max_pooling1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ global_max_pooling1d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_86[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                               │                           │                 │ dropout_59[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_87 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ concatenate_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_87[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_88 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_60[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_89 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │ dense_88[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ text_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_28 (\u001b[38;5;33mEmbedding\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)          │       \u001b[38;5;34m2,731,900\u001b[0m │ text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_22 (\u001b[38;5;33mConv1D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │          \u001b[38;5;34m19,264\u001b[0m │ embedding_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_24 (\u001b[38;5;33mConv1D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │          \u001b[38;5;34m25,664\u001b[0m │ embedding_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_26 (\u001b[38;5;33mConv1D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │          \u001b[38;5;34m32,064\u001b[0m │ embedding_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_56 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ conv1d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_57 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ conv1d_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_58 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ conv1d_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_14              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ dropout_56[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_15              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ dropout_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_16              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ dropout_58[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_23 (\u001b[38;5;33mConv1D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │           \u001b[38;5;34m6,176\u001b[0m │ max_pooling1d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_25 (\u001b[38;5;33mConv1D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │           \u001b[38;5;34m8,224\u001b[0m │ max_pooling1d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_27 (\u001b[38;5;33mConv1D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │          \u001b[38;5;34m10,272\u001b[0m │ max_pooling1d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ numerical_input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_max_pooling1d_6        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ conv1d_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_max_pooling1d_7        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ conv1d_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_max_pooling1d_8        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ conv1d_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_86 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │             \u001b[38;5;34m480\u001b[0m │ numerical_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_28 (\u001b[38;5;33mConcatenate\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ global_max_pooling1d_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ global_max_pooling1d_7[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ global_max_pooling1d_8[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_59 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_86[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_29 (\u001b[38;5;33mConcatenate\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ concatenate_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                               │                           │                 │ dropout_59[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_87 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ concatenate_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_60 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_87[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_88 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_60[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_89 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                 │             \u001b[38;5;34m325\u001b[0m │ dense_88[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,859,137</span> (10.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,859,137\u001b[0m (10.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,859,137</span> (10.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,859,137\u001b[0m (10.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training CNN Model...\n",
      "Epoch 1/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 36ms/step - accuracy: 0.2584 - loss: 2.6991 - val_accuracy: 0.0985 - val_loss: 2.1314 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 35ms/step - accuracy: 0.3746 - loss: 1.9317 - val_accuracy: 0.4390 - val_loss: 1.6459 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 35ms/step - accuracy: 0.5073 - loss: 1.6871 - val_accuracy: 0.4346 - val_loss: 1.6381 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 36ms/step - accuracy: 0.5852 - loss: 1.4805 - val_accuracy: 0.4765 - val_loss: 1.7161 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 35ms/step - accuracy: 0.6423 - loss: 1.2846 - val_accuracy: 0.4610 - val_loss: 1.6083 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 36ms/step - accuracy: 0.6798 - loss: 1.1119 - val_accuracy: 0.5096 - val_loss: 1.6114 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 35ms/step - accuracy: 0.7033 - loss: 1.0069 - val_accuracy: 0.5419 - val_loss: 1.5621 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 36ms/step - accuracy: 0.7295 - loss: 0.8687 - val_accuracy: 0.5743 - val_loss: 1.5486 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 36ms/step - accuracy: 0.7501 - loss: 0.8072 - val_accuracy: 0.5324 - val_loss: 1.6034 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 36ms/step - accuracy: 0.7608 - loss: 0.7677 - val_accuracy: 0.4713 - val_loss: 1.9239 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 36ms/step - accuracy: 0.7664 - loss: 0.7458 - val_accuracy: 0.5397 - val_loss: 1.7209 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 36ms/step - accuracy: 0.7820 - loss: 0.7010 - val_accuracy: 0.5360 - val_loss: 1.6948 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 38ms/step - accuracy: 0.7913 - loss: 0.6596 - val_accuracy: 0.5449 - val_loss: 1.8209 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 36ms/step - accuracy: 0.8161 - loss: 0.5752 - val_accuracy: 0.5757 - val_loss: 1.6946 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 36ms/step - accuracy: 0.8405 - loss: 0.4643 - val_accuracy: 0.5824 - val_loss: 1.7211 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 36ms/step - accuracy: 0.8479 - loss: 0.4301 - val_accuracy: 0.5985 - val_loss: 1.6687 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 36ms/step - accuracy: 0.8621 - loss: 0.3911 - val_accuracy: 0.5919 - val_loss: 1.7312 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 36ms/step - accuracy: 0.8723 - loss: 0.3732 - val_accuracy: 0.5743 - val_loss: 2.0004 - learning_rate: 5.0000e-04\n",
      "\n",
      "Evaluating CNN Model...\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "\n",
      "CNN Model Results:\n",
      "Accuracy: 0.5388\n",
      "F1-Score (Weighted): 0.5901\n",
      "F1-Score (Macro): 0.3388\n",
      "AUC Score: 0.8425\n"
     ]
    }
   ],
   "source": [
    "# model_configs = [\n",
    "#    ('LSTM Model', model_builder.create_lstm_model),\n",
    "#    ('BiLSTM with Attention', model_builder.create_bilstm_attention_model),\n",
    "#    ('CNN Model', model_builder.create_cnn_model),\n",
    "#    ('Transformer Model', model_builder.create_transformer_model),\n",
    "#    ('Hybrid CNN-LSTM', model_builder.create_hybrid_cnn_lstm_model)\n",
    "# ]\n",
    "\n",
    "\n",
    "# Initialize model builder\n",
    "model_builder = DeepLearningModels(vocab_size, max_len, num_features, num_classes)\n",
    "\n",
    "#'CNN Model', model_builder.create_cnn_model)\n",
    "# Define models to train\n",
    "model_configs = [\n",
    "    ('CNN Model', model_builder.create_cnn_model)\n",
    "]\n",
    "\n",
    "# Train and evaluate all models\n",
    "\n",
    "for model_name, model_func in model_configs:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Building and training {model_name}\")\n",
    "    print('='*50)\n",
    "    \n",
    "    # Create and compile model\n",
    "    model = model_func()\n",
    "    model = model_builder.compile_model(model)\n",
    "    \n",
    "    print(f\"\\n{model_name} Architecture:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Train model\n",
    "    model, history = model_builder.train_model(\n",
    "        model, model_name,\n",
    "        X_text_train_balanced, X_num_train_balanced, y_train_balanced,\n",
    "        X_text_val, X_num_val, y_val,\n",
    "        class_weights, epochs=50\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    model_builder.plot_training_history(model_name)\n",
    "    \n",
    "    # Evaluate model\n",
    "    results = model_builder.evaluate_model(\n",
    "        model, model_name, X_text_test, X_num_test, y_test, class_names\n",
    "    )\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    model_builder.plot_confusion_matrix(results, class_names)\n",
    "    \n",
    "    all_results.append(results)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"F1-Score (Weighted): {results['f1_weighted']:.4f}\")\n",
    "    print(f\"F1-Score (Macro): {results['f1_macro']:.4f}\")\n",
    "    print(f\"AUC Score: {results['auc_score']:.4f}\")\n",
    "    \n",
    "    # Save results\n",
    "    with open('data/model_results.pkl', 'wb') as f:\n",
    "        pickle.dump(all_results, f)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7c9ff112-9ab0-4497-936a-bf313fd1b279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Building and training Transformer Model\n",
      "==================================================\n",
      "\n",
      "Transformer Model Architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_22\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_22\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ text_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,731,900</span> │ text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_10       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">38,788</span> │ add_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], add_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],              │\n",
       "│                               │                           │                 │ dropout_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_13        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │ add_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_90 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,856</span> │ layer_normalization_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_90[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_91 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,700</span> │ dropout_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_91[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_14        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │ add_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_11       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">38,788</span> │ layer_normalization_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)          │                           │                 │ layer_normalization_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dropout_65[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_15        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │ add_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_92 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,856</span> │ layer_normalization_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_92[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_93 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,700</span> │ dropout_66[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                               │                           │                 │ dense_93[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ numerical_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_16        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │ add_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_94 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> │ numerical_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_11   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_94[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_pooling1d_… │\n",
       "│                               │                           │                 │ dropout_67[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_95 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,024</span> │ concatenate_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_95[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_96 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_68[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_97 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │ dense_96[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ text_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_29 (\u001b[38;5;33mEmbedding\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)          │       \u001b[38;5;34m2,731,900\u001b[0m │ text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_16 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │ embedding_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_10       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)          │          \u001b[38;5;34m38,788\u001b[0m │ add_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], add_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_62 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │ multi_head_attention_10[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_17 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │ add_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],              │\n",
       "│                               │                           │                 │ dropout_62[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_13        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)          │             \u001b[38;5;34m200\u001b[0m │ add_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_90 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)          │          \u001b[38;5;34m25,856\u001b[0m │ layer_normalization_13[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_63 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │ dense_90[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_91 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)          │          \u001b[38;5;34m25,700\u001b[0m │ dropout_63[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_18 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_13[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_91[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_14        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)          │             \u001b[38;5;34m200\u001b[0m │ add_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_11       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)          │          \u001b[38;5;34m38,788\u001b[0m │ layer_normalization_14[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)          │                           │                 │ layer_normalization_14[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_65 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │ multi_head_attention_11[\u001b[38;5;34m0\u001b[0m… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_19 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_14[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dropout_65[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_15        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)          │             \u001b[38;5;34m200\u001b[0m │ add_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_92 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)          │          \u001b[38;5;34m25,856\u001b[0m │ layer_normalization_15[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_66 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │ dense_92[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_93 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)          │          \u001b[38;5;34m25,700\u001b[0m │ dropout_66[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_20 (\u001b[38;5;33mAdd\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_15[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                               │                           │                 │ dense_93[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ numerical_input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_16        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)          │             \u001b[38;5;34m200\u001b[0m │ add_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_94 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │             \u001b[38;5;34m480\u001b[0m │ numerical_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_11   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_16[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_67 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ dense_94[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_30 (\u001b[38;5;33mConcatenate\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m132\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ global_average_pooling1d_… │\n",
       "│                               │                           │                 │ dropout_67[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_95 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m17,024\u001b[0m │ concatenate_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_68 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense_95[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_96 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_68[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_97 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                 │             \u001b[38;5;34m325\u001b[0m │ dense_96[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,939,473</span> (11.21 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,939,473\u001b[0m (11.21 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,939,473</span> (11.21 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,939,473\u001b[0m (11.21 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Transformer Model...\n",
      "Epoch 1/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 119ms/step - accuracy: 0.2573 - loss: 2.8454 - val_accuracy: 0.2868 - val_loss: 1.8903 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 116ms/step - accuracy: 0.3511 - loss: 1.9867 - val_accuracy: 0.4316 - val_loss: 1.6883 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 117ms/step - accuracy: 0.4330 - loss: 1.8469 - val_accuracy: 0.5868 - val_loss: 1.3917 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 117ms/step - accuracy: 0.4962 - loss: 1.7549 - val_accuracy: 0.4368 - val_loss: 1.7976 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 117ms/step - accuracy: 0.5257 - loss: 1.6704 - val_accuracy: 0.3956 - val_loss: 2.0351 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 118ms/step - accuracy: 0.5534 - loss: 1.5829 - val_accuracy: 0.4228 - val_loss: 1.8637 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 118ms/step - accuracy: 0.5719 - loss: 1.4992 - val_accuracy: 0.3971 - val_loss: 1.9006 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 118ms/step - accuracy: 0.6098 - loss: 1.3780 - val_accuracy: 0.4647 - val_loss: 1.9253 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 118ms/step - accuracy: 0.6486 - loss: 1.2668 - val_accuracy: 0.5419 - val_loss: 1.7416 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 118ms/step - accuracy: 0.6710 - loss: 1.1687 - val_accuracy: 0.5066 - val_loss: 1.8301 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 119ms/step - accuracy: 0.6926 - loss: 1.0973 - val_accuracy: 0.5088 - val_loss: 1.8590 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 119ms/step - accuracy: 0.7133 - loss: 1.0261 - val_accuracy: 0.5066 - val_loss: 1.7920 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 119ms/step - accuracy: 0.7231 - loss: 0.9937 - val_accuracy: 0.4963 - val_loss: 1.9750 - learning_rate: 5.0000e-04\n",
      "\n",
      "Evaluating Transformer Model...\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 65ms/step\n",
      "\n",
      "Transformer Model Results:\n",
      "Accuracy: 0.5535\n",
      "F1-Score (Weighted): 0.6152\n",
      "F1-Score (Macro): 0.3667\n",
      "AUC Score: 0.8853\n"
     ]
    }
   ],
   "source": [
    "# model_configs = [\n",
    "#    ('LSTM Model', model_builder.create_lstm_model),\n",
    "#    ('BiLSTM with Attention', model_builder.create_bilstm_attention_model),\n",
    "#    ('CNN Model', model_builder.create_cnn_model),\n",
    "#    ('Transformer Model', model_builder.create_transformer_model),\n",
    "#    ('Hybrid CNN-LSTM', model_builder.create_hybrid_cnn_lstm_model)\n",
    "# ]\n",
    "\n",
    "\n",
    "# Initialize model builder\n",
    "model_builder = DeepLearningModels(vocab_size, max_len, num_features, num_classes)\n",
    "\n",
    "#'Transformer Model', model_builder.create_transformer_model)\n",
    "# Define models to train\n",
    "model_configs = [\n",
    "    ('Transformer Model', model_builder.create_transformer_model)\n",
    "]\n",
    "\n",
    "# Train and evaluate all models\n",
    "\n",
    "for model_name, model_func in model_configs:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Building and training {model_name}\")\n",
    "    print('='*50)\n",
    "    \n",
    "    # Create and compile model\n",
    "    model = model_func()\n",
    "    model = model_builder.compile_model(model)\n",
    "    \n",
    "    print(f\"\\n{model_name} Architecture:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Train model\n",
    "    model, history = model_builder.train_model(\n",
    "        model, model_name,\n",
    "        X_text_train_balanced, X_num_train_balanced, y_train_balanced,\n",
    "        X_text_val, X_num_val, y_val,\n",
    "        class_weights, epochs=50\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    model_builder.plot_training_history(model_name)\n",
    "    \n",
    "    # Evaluate model\n",
    "    results = model_builder.evaluate_model(\n",
    "        model, model_name, X_text_test, X_num_test, y_test, class_names\n",
    "    )\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    model_builder.plot_confusion_matrix(results, class_names)\n",
    "    \n",
    "    all_results.append(results)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"F1-Score (Weighted): {results['f1_weighted']:.4f}\")\n",
    "    print(f\"F1-Score (Macro): {results['f1_macro']:.4f}\")\n",
    "    print(f\"AUC Score: {results['auc_score']:.4f}\")\n",
    "    \n",
    "    # Save results\n",
    "    with open('data/model_results.pkl', 'wb') as f:\n",
    "        pickle.dump(all_results, f)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b8179cb7-404c-405d-8679-9122bd68afb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Building and training Hybrid CNN-LSTM\n",
      "==================================================\n",
      "\n",
      "Hybrid CNN-LSTM Architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_23\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_23\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ text_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,731,900</span> │ text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">38,528</span> │ embedding_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">64,128</span> │ embedding_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_17              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_18              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                               │                           │                 │ max_pooling1d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ concatenate_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ numerical_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> │ batch_normalization_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_98 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> │ numerical_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],             │\n",
       "│                               │                           │                 │ dense_98[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_99 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,608</span> │ concatenate_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_100 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │ dense_99[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ text_input (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_31 (\u001b[38;5;33mEmbedding\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)          │       \u001b[38;5;34m2,731,900\u001b[0m │ text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_28 (\u001b[38;5;33mConv1D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │          \u001b[38;5;34m38,528\u001b[0m │ embedding_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_29 (\u001b[38;5;33mConv1D\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │          \u001b[38;5;34m64,128\u001b[0m │ embedding_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_17              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ conv1d_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d_18              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ conv1d_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)                │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_31 (\u001b[38;5;33mConcatenate\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ max_pooling1d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                               │                           │                 │ max_pooling1d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │           \u001b[38;5;34m1,024\u001b[0m │ concatenate_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ numerical_input (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_20 (\u001b[38;5;33mLSTM\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │         \u001b[38;5;34m197,120\u001b[0m │ batch_normalization_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_98 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │             \u001b[38;5;34m480\u001b[0m │ numerical_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate_32 (\u001b[38;5;33mConcatenate\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ lstm_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],             │\n",
       "│                               │                           │                 │ dense_98[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_99 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m20,608\u001b[0m │ concatenate_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_100 (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                 │             \u001b[38;5;34m645\u001b[0m │ dense_99[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,054,433</span> (11.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,054,433\u001b[0m (11.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,053,921</span> (11.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,053,921\u001b[0m (11.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Hybrid CNN-LSTM...\n",
      "Epoch 1/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 161ms/step - accuracy: 0.2671 - loss: 2.1110 - val_accuracy: 0.1110 - val_loss: 2.6376 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 158ms/step - accuracy: 0.3372 - loss: 1.9020 - val_accuracy: 0.1949 - val_loss: 2.5058 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 161ms/step - accuracy: 0.4104 - loss: 1.7548 - val_accuracy: 0.4125 - val_loss: 1.7920 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 158ms/step - accuracy: 0.5228 - loss: 1.5784 - val_accuracy: 0.4941 - val_loss: 1.7985 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 159ms/step - accuracy: 0.5841 - loss: 1.4384 - val_accuracy: 0.5294 - val_loss: 1.6735 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 160ms/step - accuracy: 0.6276 - loss: 1.3039 - val_accuracy: 0.5654 - val_loss: 1.6237 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 159ms/step - accuracy: 0.6716 - loss: 1.1696 - val_accuracy: 0.5544 - val_loss: 1.7858 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 160ms/step - accuracy: 0.6990 - loss: 1.0496 - val_accuracy: 0.4860 - val_loss: 2.0714 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 160ms/step - accuracy: 0.7330 - loss: 0.9118 - val_accuracy: 0.5765 - val_loss: 1.8386 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10540s\u001b[0m 8s/step - accuracy: 0.7539 - loss: 0.8342 - val_accuracy: 0.6059 - val_loss: 1.8356 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 168ms/step - accuracy: 0.7790 - loss: 0.7264 - val_accuracy: 0.5463 - val_loss: 2.0757 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 176ms/step - accuracy: 0.8070 - loss: 0.6009 - val_accuracy: 0.5544 - val_loss: 2.1054 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 184ms/step - accuracy: 0.8398 - loss: 0.4620 - val_accuracy: 0.5669 - val_loss: 2.1853 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 179ms/step - accuracy: 0.8547 - loss: 0.4034 - val_accuracy: 0.5919 - val_loss: 2.1480 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 172ms/step - accuracy: 0.8709 - loss: 0.3529 - val_accuracy: 0.5890 - val_loss: 2.3267 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m1242/1242\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 171ms/step - accuracy: 0.8762 - loss: 0.3364 - val_accuracy: 0.5868 - val_loss: 2.3380 - learning_rate: 5.0000e-04\n",
      "\n",
      "Evaluating Hybrid CNN-LSTM...\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 88ms/step\n",
      "\n",
      "Hybrid CNN-LSTM Results:\n",
      "Accuracy: 0.5362\n",
      "F1-Score (Weighted): 0.5848\n",
      "F1-Score (Macro): 0.3367\n",
      "AUC Score: 0.8150\n"
     ]
    }
   ],
   "source": [
    "# model_configs = [\n",
    "#    ('LSTM Model', model_builder.create_lstm_model),\n",
    "#    ('BiLSTM with Attention', model_builder.create_bilstm_attention_model),\n",
    "#    ('CNN Model', model_builder.create_cnn_model),\n",
    "#    ('Transformer Model', model_builder.create_transformer_model),\n",
    "#    ('Hybrid CNN-LSTM', model_builder.create_hybrid_cnn_lstm_model)\n",
    "# ]\n",
    "\n",
    "\n",
    "# Initialize model builder\n",
    "model_builder = DeepLearningModels(vocab_size, max_len, num_features, num_classes)\n",
    "\n",
    "#'Hybrid CNN-LSTM', model_builder.create_hybrid_cnn_lstm_model)\n",
    "# Define models to train\n",
    "model_configs = [\n",
    "    ('Hybrid CNN-LSTM', model_builder.create_hybrid_cnn_lstm_model_modified)\n",
    "]\n",
    "\n",
    "# Train and evaluate all models\n",
    "\n",
    "for model_name, model_func in model_configs:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Building and training {model_name}\")\n",
    "    print('='*50)\n",
    "    \n",
    "    # Create and compile model\n",
    "    model = model_func()\n",
    "    model = model_builder.compile_model(model)\n",
    "    \n",
    "    print(f\"\\n{model_name} Architecture:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Train model\n",
    "    model, history = model_builder.train_model(\n",
    "        model, model_name,\n",
    "        X_text_train_balanced, X_num_train_balanced, y_train_balanced,\n",
    "        X_text_val, X_num_val, y_val,\n",
    "        class_weights, epochs=50\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    model_builder.plot_training_history(model_name)\n",
    "    \n",
    "    # Evaluate model\n",
    "    results = model_builder.evaluate_model(\n",
    "        model, model_name, X_text_test, X_num_test, y_test, class_names\n",
    "    )\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    model_builder.plot_confusion_matrix(results, class_names)\n",
    "    \n",
    "    all_results.append(results)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"F1-Score (Weighted): {results['f1_weighted']:.4f}\")\n",
    "    print(f\"F1-Score (Macro): {results['f1_macro']:.4f}\")\n",
    "    print(f\"AUC Score: {results['auc_score']:.4f}\")\n",
    "    \n",
    "    # Save results\n",
    "    with open('data/model_results.pkl', 'wb') as f:\n",
    "        pickle.dump(all_results, f)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0d1f634f-6aaa-4bf5-9101-d83186bd9888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'model_name': 'LSTM Model', 'accuracy': 0.5277675616035307, 'f1_weighted': 0.5829629168629785, 'f1_macro': 0.3485824084333385, 'auc_score': np.float64(0.8413423767976255), 'precision': array([0.88469185, 0.        , 0.09256198, 0.17560976, 0.77281947]), 'recall': array([0.62853107, 0.        , 0.43410853, 0.49090909, 0.48596939]), 'f1_per_class': array([0.73492981, 0.        , 0.15258856, 0.25868263, 0.59671104]), 'support': array([1416,  170,  129,  220,  784]), 'classification_report': {'Rating 1': {'precision': 0.8846918489065606, 'recall': 0.6285310734463276, 'f1-score': 0.7349298100743188, 'support': 1416.0}, 'Rating 2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 170.0}, 'Rating 3': {'precision': 0.09256198347107437, 'recall': 0.43410852713178294, 'f1-score': 0.15258855585831063, 'support': 129.0}, 'Rating 4': {'precision': 0.17560975609756097, 'recall': 0.4909090909090909, 'f1-score': 0.25868263473053893, 'support': 220.0}, 'Rating 5': {'precision': 0.7728194726166329, 'recall': 0.48596938775510207, 'f1-score': 0.5967110415035238, 'support': 784.0}, 'accuracy': 0.5277675616035307, 'macro avg': {'precision': 0.38513661221836576, 'recall': 0.4079036158484607, 'f1-score': 0.3485824084333385, 'support': 2719.0}, 'weighted avg': {'precision': 0.7021657840354403, 'recall': 0.5277675616035307, 'f1-score': 0.5829629168629785, 'support': 2719.0}}, 'confusion_matrix': array([[890,   0, 353, 131,  42],\n",
      "       [ 57,   0,  70,  36,   7],\n",
      "       [ 23,   0,  56,  39,  11],\n",
      "       [ 14,   0,  46, 108,  52],\n",
      "       [ 22,   0,  80, 301, 381]]), 'y_pred': array([2, 0, 2, ..., 4, 3, 4], shape=(2719,)), 'y_pred_proba': array([[6.7643919e-03, 5.6565175e-04, 9.1754866e-01, 6.1936285e-02,\n",
      "        1.3184888e-02],\n",
      "       [9.9298394e-01, 7.2940442e-05, 5.0419155e-03, 7.3039075e-05,\n",
      "        1.8283016e-03],\n",
      "       [1.2299168e-02, 1.1711596e-04, 9.6513903e-01, 1.5683891e-02,\n",
      "        6.7608310e-03],\n",
      "       ...,\n",
      "       [2.8870344e-01, 2.7082391e-02, 5.1787253e-02, 1.8202278e-01,\n",
      "        4.5040420e-01],\n",
      "       [2.1227967e-02, 5.7677841e-03, 3.9336119e-02, 5.2585590e-01,\n",
      "        4.0781224e-01],\n",
      "       [1.8324727e-03, 1.3693678e-05, 1.6332828e-05, 2.9370496e-02,\n",
      "        9.6876717e-01]], shape=(2719, 5), dtype=float32)}, {'model_name': 'BiLSTM with Attention', 'accuracy': 0.4200073556454579, 'f1_weighted': 0.49804637900143683, 'f1_macro': 0.3046568622071349, 'auc_score': np.float64(0.8495270429311433), 'precision': array([0.91596639, 0.        , 0.05916586, 0.14484127, 0.7860781 ]), 'recall': array([0.38488701, 0.        , 0.47286822, 0.33181818, 0.59056122]), 'f1_per_class': array([0.5420189 , 0.        , 0.10517241, 0.20165746, 0.67443554]), 'support': array([1416,  170,  129,  220,  784]), 'classification_report': {'Rating 1': {'precision': 0.9159663865546218, 'recall': 0.3848870056497175, 'f1-score': 0.5420188960716061, 'support': 1416.0}, 'Rating 2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 170.0}, 'Rating 3': {'precision': 0.05916585838991271, 'recall': 0.4728682170542636, 'f1-score': 0.10517241379310345, 'support': 129.0}, 'Rating 4': {'precision': 0.14484126984126985, 'recall': 0.33181818181818185, 'f1-score': 0.20165745856353592, 'support': 220.0}, 'Rating 5': {'precision': 0.7860780984719864, 'recall': 0.5905612244897959, 'f1-score': 0.674435542607429, 'support': 784.0}, 'accuracy': 0.4200073556454579, 'macro avg': {'precision': 0.38121032265155813, 'recall': 0.35602692580239176, 'f1-score': 0.3046568622071349, 'support': 2719.0}, 'weighted avg': {'precision': 0.7182019520635381, 'recall': 0.4200073556454579, 'f1-score': 0.49804637900143683, 'support': 2719.0}}, 'confusion_matrix': array([[545,   0, 726, 126,  19],\n",
      "       [ 26,   0, 103,  34,   7],\n",
      "       [ 10,   0,  61,  41,  17],\n",
      "       [  7,   0,  57,  73,  83],\n",
      "       [  7,   0,  84, 230, 463]]), 'y_pred': array([3, 2, 2, ..., 2, 2, 4], shape=(2719,)), 'y_pred_proba': array([[1.6507527e-02, 4.2942414e-04, 1.0720099e-01, 7.1992868e-01,\n",
      "        1.5593337e-01],\n",
      "       [3.3352333e-01, 1.5632549e-02, 5.4699254e-01, 3.8709141e-02,\n",
      "        6.5142460e-02],\n",
      "       [2.3223277e-02, 7.2184129e-04, 8.1069654e-01, 1.4951582e-01,\n",
      "        1.5842568e-02],\n",
      "       ...,\n",
      "       [2.5401169e-01, 4.6325085e-04, 5.7706994e-01, 1.5177144e-01,\n",
      "        1.6683685e-02],\n",
      "       [2.5289086e-01, 7.5471355e-03, 4.8262227e-01, 1.9657090e-01,\n",
      "        6.0368817e-02],\n",
      "       [1.8094531e-03, 7.2058995e-04, 7.3506725e-03, 1.6155338e-01,\n",
      "        8.2856596e-01]], shape=(2719, 5), dtype=float32)}, {'model_name': 'CNN Model', 'accuracy': 0.5388010297903641, 'f1_weighted': 0.5900695774234097, 'f1_macro': 0.33880091387878675, 'auc_score': np.float64(0.8424500521412964), 'precision': array([0.88469388, 0.        , 0.07346939, 0.13083049, 0.75609756]), 'recall': array([0.61228814, 0.        , 0.13953488, 0.52272727, 0.59311224]), 'f1_per_class': array([0.72370618, 0.        , 0.09625668, 0.20928116, 0.66476054]), 'support': array([1416,  170,  129,  220,  784]), 'classification_report': {'Rating 1': {'precision': 0.8846938775510204, 'recall': 0.6122881355932204, 'f1-score': 0.7237061769616027, 'support': 1416.0}, 'Rating 2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 170.0}, 'Rating 3': {'precision': 0.07346938775510205, 'recall': 0.13953488372093023, 'f1-score': 0.0962566844919786, 'support': 129.0}, 'Rating 4': {'precision': 0.13083048919226395, 'recall': 0.5227272727272727, 'f1-score': 0.20928116469517744, 'support': 220.0}, 'Rating 5': {'precision': 0.7560975609756098, 'recall': 0.5931122448979592, 'f1-score': 0.6647605432451751, 'support': 784.0}, 'accuracy': 0.5388010297903641, 'macro avg': {'precision': 0.36901826309479924, 'recall': 0.37353250738787647, 'f1-score': 0.33880091387878675, 'support': 2719.0}, 'weighted avg': {'precision': 0.6928162107612464, 'recall': 0.5388010297903641, 'f1-score': 0.5900695774234097, 'support': 2719.0}}, 'confusion_matrix': array([[867,   0, 168, 331,  50],\n",
      "       [ 56,   0,  20,  80,  14],\n",
      "       [ 25,   0,  18,  72,  14],\n",
      "       [ 15,   0,  18, 115,  72],\n",
      "       [ 17,   0,  21, 281, 465]]), 'y_pred': array([3, 0, 2, ..., 0, 4, 4], shape=(2719,)), 'y_pred_proba': array([[1.2369758e-02, 4.2940860e-04, 1.9161308e-03, 7.7402997e-01,\n",
      "        2.1125469e-01],\n",
      "       [4.2687789e-01, 3.7497021e-02, 2.8684160e-01, 9.7213209e-02,\n",
      "        1.5157025e-01],\n",
      "       [3.9905062e-04, 3.2228547e-07, 9.9931169e-01, 5.3471744e-05,\n",
      "        2.3545056e-04],\n",
      "       ...,\n",
      "       [9.1012466e-01, 9.1173006e-03, 4.6307324e-03, 1.3070309e-02,\n",
      "        6.3057035e-02],\n",
      "       [1.2194451e-02, 1.1933582e-03, 3.8659633e-03, 4.5968735e-01,\n",
      "        5.2305883e-01],\n",
      "       [2.5294394e-06, 1.0146361e-10, 6.3451489e-10, 2.8761139e-03,\n",
      "        9.9712139e-01]], shape=(2719, 5), dtype=float32)}, {'model_name': 'Transformer Model', 'accuracy': 0.553512320706142, 'f1_weighted': 0.6152473799254324, 'f1_macro': 0.3667425555348184, 'auc_score': np.float64(0.8852834171636483), 'precision': array([0.91101695, 0.        , 0.08478513, 0.20138889, 0.82108626]), 'recall': array([0.60734463, 0.        , 0.56589147, 0.26363636, 0.65561224]), 'f1_per_class': array([0.72881356, 0.        , 0.14747475, 0.22834646, 0.72907801]), 'support': array([1416,  170,  129,  220,  784]), 'classification_report': {'Rating 1': {'precision': 0.9110169491525424, 'recall': 0.6073446327683616, 'f1-score': 0.7288135593220338, 'support': 1416.0}, 'Rating 2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 170.0}, 'Rating 3': {'precision': 0.08478513356562137, 'recall': 0.5658914728682171, 'f1-score': 0.14747474747474748, 'support': 129.0}, 'Rating 4': {'precision': 0.2013888888888889, 'recall': 0.2636363636363636, 'f1-score': 0.2283464566929134, 'support': 220.0}, 'Rating 5': {'precision': 0.8210862619808307, 'recall': 0.6556122448979592, 'f1-score': 0.7290780141843972, 'support': 784.0}, 'accuracy': 0.553512320706142, 'macro avg': {'precision': 0.40365544671757664, 'recall': 0.4184969428341804, 'f1-score': 0.3667425555348184, 'support': 2719.0}, 'weighted avg': {'precision': 0.7315095502679264, 'recall': 0.553512320706142, 'f1-score': 0.6152473799254324, 'support': 2719.0}}, 'confusion_matrix': array([[860,   0, 522,  28,   6],\n",
      "       [ 46,   0, 106,  13,   5],\n",
      "       [ 17,   0,  73,  27,  12],\n",
      "       [ 10,   0,  63,  58,  89],\n",
      "       [ 11,   0,  97, 162, 514]]), 'y_pred': array([2, 0, 2, ..., 0, 2, 4], shape=(2719,)), 'y_pred_proba': array([[5.8491291e-03, 2.0644281e-03, 5.0402546e-01, 4.0025350e-01,\n",
      "        8.7807506e-02],\n",
      "       [6.2150818e-01, 7.4584680e-03, 2.4765389e-01, 9.0598859e-02,\n",
      "        3.2780651e-02],\n",
      "       [1.5723515e-02, 2.4141620e-03, 6.0441637e-01, 3.2585275e-01,\n",
      "        5.1593110e-02],\n",
      "       ...,\n",
      "       [9.5040488e-01, 4.6971425e-05, 4.3682326e-02, 4.9651312e-03,\n",
      "        9.0064376e-04],\n",
      "       [3.0063942e-01, 1.9299388e-02, 3.8177916e-01, 2.2381674e-01,\n",
      "        7.4465327e-02],\n",
      "       [1.9390130e-04, 1.5484213e-04, 2.0539066e-02, 3.2384363e-01,\n",
      "        6.5526849e-01]], shape=(2719, 5), dtype=float32)}, {'model_name': 'Hybrid CNN-LSTM', 'accuracy': 0.536226553880103, 'f1_weighted': 0.5847726433786831, 'f1_macro': 0.33671562595947013, 'auc_score': np.float64(0.8149666038897083), 'precision': array([0.87816764, 0.        , 0.08298755, 0.13541667, 0.69133858]), 'recall': array([0.63629944, 0.        , 0.31007752, 0.35454545, 0.55994898]), 'f1_per_class': array([0.73791974, 0.        , 0.1309329 , 0.1959799 , 0.6187456 ]), 'support': array([1416,  170,  129,  220,  784]), 'classification_report': {'Rating 1': {'precision': 0.878167641325536, 'recall': 0.6362994350282486, 'f1-score': 0.737919737919738, 'support': 1416.0}, 'Rating 2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 170.0}, 'Rating 3': {'precision': 0.08298755186721991, 'recall': 0.31007751937984496, 'f1-score': 0.1309328968903437, 'support': 129.0}, 'Rating 4': {'precision': 0.13541666666666666, 'recall': 0.35454545454545455, 'f1-score': 0.19597989949748743, 'support': 220.0}, 'Rating 5': {'precision': 0.6913385826771653, 'recall': 0.5599489795918368, 'f1-score': 0.6187455954897816, 'support': 784.0}, 'accuracy': 0.536226553880103, 'macro avg': {'precision': 0.3575820885073176, 'recall': 0.37217427770907696, 'f1-score': 0.33671562595947013, 'support': 2719.0}, 'weighted avg': {'precision': 0.6715674475150404, 'recall': 0.536226553880103, 'f1-score': 0.5847726433786831, 'support': 2719.0}}, 'confusion_matrix': array([[901,   0, 277, 169,  69],\n",
      "       [ 54,   0,  53,  47,  16],\n",
      "       [ 24,   0,  40,  41,  24],\n",
      "       [ 18,   0,  37,  78,  87],\n",
      "       [ 29,   0,  75, 241, 439]]), 'y_pred': array([3, 0, 2, ..., 3, 2, 4], shape=(2719,)), 'y_pred_proba': array([[2.9652936e-02, 1.3747801e-04, 6.5199437e-04, 5.9221905e-01,\n",
      "        3.7733859e-01],\n",
      "       [6.3430673e-01, 9.2137756e-04, 2.7154249e-01, 8.4948074e-03,\n",
      "        8.4734641e-02],\n",
      "       [1.0278965e-01, 7.8481538e-03, 7.3850894e-01, 1.3449106e-01,\n",
      "        1.6362144e-02],\n",
      "       ...,\n",
      "       [2.7277493e-01, 4.9873284e-04, 3.4917537e-02, 6.3366061e-01,\n",
      "        5.8148164e-02],\n",
      "       [3.1008393e-02, 1.2553955e-02, 5.0110412e-01, 2.8374353e-01,\n",
      "        1.7159003e-01],\n",
      "       [3.4179068e-03, 3.3519678e-05, 5.2785224e-05, 3.0452544e-02,\n",
      "        9.6604329e-01]], shape=(2719, 5), dtype=float32)}]\n"
     ]
    }
   ],
   "source": [
    "# Create comparison summary\n",
    "summary_data = []\n",
    "for result in all_results:\n",
    "    summary_data.append({\n",
    "        'Model': result['model_name'],\n",
    "        'Accuracy': result['accuracy'],\n",
    "        'F1-Weighted': result['f1_weighted'],\n",
    "        'F1-Macro': result['f1_macro'],\n",
    "        'AUC Score': result['auc_score']\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(all_results)\n",
    "#summary_df = summary_df.sort_values('F1-Weighted', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "184dacc9-55cb-4bda-8bd1-3f46edca9327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL PERFORMANCE COMPARISON\n",
      "================================================================================\n",
      "                Model  Accuracy  F1-Weighted  F1-Macro  AUC Score\n",
      "    Transformer Model    0.5535       0.6152    0.3667     0.8853\n",
      "            CNN Model    0.5388       0.5901    0.3388     0.8425\n",
      "      Hybrid CNN-LSTM    0.5362       0.5848    0.3367     0.8150\n",
      "           LSTM Model    0.5278       0.5830    0.3486     0.8413\n",
      "BiLSTM with Attention    0.4200       0.4980    0.3047     0.8495\n",
      "\n",
      "Best performing model: Transformer Model\n",
      "Best F1-Weighted Score: 0.6152\n",
      "⚠️ Model LSTM Model not found in trained models\n",
      "⚠️ Model BiLSTM with Attention not found in trained models\n",
      "⚠️ Model CNN Model not found in trained models\n",
      "⚠️ Model Transformer Model not found in trained models\n",
      "✅ Saved API-ready Hybrid CNN-LSTM package to api_models\\hybrid_cnn-lstm\n",
      "\n",
      "All models saved in API-ready format.\n",
      "You can now deploy any model by copying its directory to your API server.\n",
      "All models and results saved. Results path: api_models\\data\\model_results_20250808_122546.pkl\n"
     ]
    }
   ],
   "source": [
    "# Create comparison summary\n",
    "summary_data = []\n",
    "for result in all_results:\n",
    "    summary_data.append({\n",
    "        'Model': result['model_name'],\n",
    "        'Accuracy': result['accuracy'],\n",
    "        'F1-Weighted': result['f1_weighted'],\n",
    "        'F1-Macro': result['f1_macro'],\n",
    "        'AUC Score': result['auc_score']\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df = summary_df.sort_values('F1-Weighted', ascending=False)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "print('='*80)\n",
    "print(summary_df.to_string(index=False, float_format='%.4f'))\n",
    "\n",
    "# Save summary\n",
    "summary_df.to_csv('data/model_comparison_summary.csv', index=False)\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "metrics = ['Accuracy', 'F1-Weighted', 'F1-Macro', 'AUC Score']\n",
    "x = np.arange(len(summary_df))\n",
    "width = 0.2\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    plt.bar(x + i*width, summary_df[metric], width, label=metric, alpha=0.8)\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Deep Learning Models Performance Comparison')\n",
    "plt.xticks(x + width*1.5, summary_df['Model'], rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('charts/model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nBest performing model: {summary_df.iloc[0]['Model']}\")\n",
    "print(f\"Best F1-Weighted Score: {summary_df.iloc[0]['F1-Weighted']:.4f}\")\n",
    "\n",
    "# After training all models, save everything\n",
    "results_path = model_builder.save_all_models(all_results)\n",
    "print(f\"All models and results saved. Results path: {results_path}\")\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1ee117-9983-4d02-a4de-a0e26e8aa5bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
